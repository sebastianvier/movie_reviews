{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cd9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python in build modules:\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "## EDA libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "## Metrics (sklearn)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "## Models (sklearn)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ec5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(y_true, prediction):\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_true, prediction))\n",
    "    print(\"\\n\")\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_true, prediction))\n",
    "    print(\"\\n\")\n",
    "    print(\"Other Metrics:\")\n",
    "    print(f'Pression Score: {precision_score(y_true, prediction)}')\n",
    "    print(f'Accuracy Score: {accuracy_score(y_true, prediction)}')\n",
    "    print(f'Recall Score: {recall_score(y_true, prediction)}')\n",
    "    print(f'f1 Score {f1_score(y_true, prediction)}')\n",
    "    \n",
    "def check_model(clf, X_test, y_test):\n",
    "    prediction = clf.predict(X_test)\n",
    "    print_report(y_test, prediction)\n",
    "    \n",
    "def vectorize_X(vectorizer, X_train, X_test):\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized  = vectorizer.transform(X_test)\n",
    "    return X_train_vectorized, X_test_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ef8b2",
   "metadata": {},
   "source": [
    "### 1) Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd00805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "## Importing the data\n",
    "\n",
    "path = 'data/train/'\n",
    "\n",
    "count = 0\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "for label in ['neg','pos']:\n",
    "    filenames = os.listdir(path + label)\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        with open(os.path.join(path, label, filename), 'r') as f:\n",
    "            labels.append(1 if label == 'pos' else 0) # 1 is positve 0 is negative\n",
    "            contents.append(f.read())\n",
    "print(count)\n",
    "            \n",
    "data = pd.DataFrame({\n",
    "    'contents' : contents,\n",
    "    'labels': labels,\n",
    "\n",
    "})\n",
    "\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True) # This code will shuffle the data (just in case!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdecdb1c",
   "metadata": {},
   "source": [
    "#### Just to be clear negative is 0 and positive is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1935c7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab00242",
   "metadata": {},
   "source": [
    "Ok, the data is **completely balanced**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298663a9",
   "metadata": {},
   "source": [
    " ###### At this moment we are going to see 5 examples of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b3dd8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "\n",
      "\n",
      "I am very surprised to see such a high rating for this film, and of the few reviews that there are to be positive. I saw the movie and was pretty dissapointed. I didn't find it very enjoyable at all. It was slow, and lacks the entertainment value. Even the murder scenes are lackluster, with real close-up shots of generic stabbings that don't look good at all. And the supposed great twist ending is really not much, I did see it coming, and then the ending just seemed cliche. This movie may not get much mention, but by the little that it does get, it is overrated. I would not recommend this movie.\n",
      "\n",
      "\n",
      "Anyone giving this movie a good review obviously must have had something to do with its creation. This movie is a painful suckfest. The acting is stiff, the stock generic soundtrack is laughable, the direction is bland and strangest of all, the teacher really isn't all that attractive (making the student's blatant advances all the more awkward). The creative minds behind this trash should disband and spread out to prevent further displays of such concentrated craptitude. I'm certain that some starving kids in Africa could have used the money squandered on this project. Hell, the funds would have also seen a more enlightened purpose fueling a crack-addict; at least someone would be getting some entertainment out of it. For the sole reason that it didn't give me a terminal illness, I'll give this film a two.\n",
      "\n",
      "\n",
      "positive\n",
      "\n",
      "\n",
      "I really have to say, this was always a favorite of mine when I went to see my grandma. And it still is. It is very, very close to the book. The way it is filmed, and the players were just all excellent! I have to recommend this movie to everyone who hasn't seen it. Almost everyone I talk to hates TV movies, but this was really great! I gave it 10/10.\n",
      "\n",
      "\n",
      "If ever anyone queries whether cinema is an art form, you can do worse than pointing them at this movie.<br /><br />Quite simply it is the perfect combination of story, script, actors and cinematography ever committed to celluloid.<br /><br />The story of a doomed bomber pilot who is missed by his heavenly conductor in the English fog during the second world war, and his subsequent brushes with the celestial authorities (or is it in his head) is played with panache by David Niven and Kim Hunter and is incredibly touching - especially in the opening scenes when the doomed pilot (Niven) describes his plight to the ground radio operator (Hunter).<br /><br />The sense of otherworldliness is heightened by Jack Cardiff's photography and the incredible production designs.<br /><br />The supreme touches extend to the heaven shots appearing in black and white and earthbound scenes presented in Technicolour - this is even mentioned by the celestial conductor (a fantastic Marius Goring).<br /><br />Not only a highpoint in British cinema, but a highpoint in cinema, period.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in data.labels.unique():\n",
    "    print(\"negative\" if label ==  0 else \"positive\")\n",
    "    print(\"\\n\")\n",
    "    for content in data.contents[data.labels == label].sample(2):\n",
    "        print(content)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2f5d0",
   "metadata": {},
   "source": [
    "###### From now on I am going to be using the training data to explore the data so I can get some conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e48b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.contents\n",
    "y = data.labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54397f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edfbbc31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8387\n",
       "0    8363\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.labels.value_counts() # Just checking the proportions haven't change much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9304e8",
   "metadata": {},
   "source": [
    "### Does it has to do something with length?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034f50c",
   "metadata": {},
   "source": [
    "###### Mean of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb077e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of all reviews: 1328.28\n",
      "Mean length in positive reviews: 1352.3945391677596\n",
      "Mean length in negative reviews: 1304.1033122085375\n",
      "Ratio positive: 1.0181547107294844\n",
      "Ration negative: 0.9817985004731966\n"
     ]
    }
   ],
   "source": [
    "mean_length_full = np.round(X_train.map(len).mean(),2)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "mean_lenght_pos = train_df[train_df.labels == 1].contents.map(len).mean()\n",
    "mean_length_neg = train_df[train_df.labels == 0].contents.map(len).mean()\n",
    "ratio_pos =  mean_lenght_pos / mean_length_full\n",
    "ratio_neg =  mean_length_neg / mean_length_full\n",
    "\n",
    "print(f'Mean length of all reviews: {mean_length_full}')\n",
    "print(f'Mean length in positive reviews: {mean_lenght_pos}')\n",
    "print(f'Mean length in negative reviews: {mean_length_neg}')\n",
    "print(f'Ratio positive: {ratio_pos}')\n",
    "print(f'Ration negative: {ratio_neg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd11a0",
   "metadata": {},
   "source": [
    "We can run an **A/B test** here, but there is an indication that the **length** of the commentary has **nothing to do** with the idea if it is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587a175",
   "metadata": {},
   "source": [
    "###### Describing of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c84568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the length of model when positive:\n",
      "count     8387.000000\n",
      "mean      1352.394539\n",
      "std       1053.673512\n",
      "min         70.000000\n",
      "25%        695.000000\n",
      "50%        982.000000\n",
      "75%       1659.500000\n",
      "max      13704.000000\n",
      "Name: contents, dtype: float64\n",
      "\n",
      "\n",
      "Describe the length of model when negative:\n",
      "count    8363.000000\n",
      "mean     1304.103312\n",
      "std       963.063593\n",
      "min        53.000000\n",
      "25%       710.000000\n",
      "50%       981.000000\n",
      "75%      1554.000000\n",
      "max      8754.000000\n",
      "Name: contents, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Describe the length of model when positive:')\n",
    "print(train_df[train_df.labels == 1].contents.map(len).describe())\n",
    "print('\\n')\n",
    "print('Describe the length of model when negative:')\n",
    "print(train_df[train_df.labels == 0].contents.map(len).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5e50f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage: 80\n",
      "positive\n",
      "1917.0\n",
      "negative\n",
      "1799.0\n",
      "percentage: 84\n",
      "positive\n",
      "2168.7199999999993\n",
      "negative\n",
      "2015.0\n",
      "percentage: 88\n",
      "positive\n",
      "2514.0\n",
      "negative\n",
      "2328.120000000001\n",
      "percentage: 92\n",
      "positive\n",
      "3005.0\n",
      "negative\n",
      "2755.12\n",
      "percentage: 96\n",
      "positive\n",
      "3815.119999999999\n",
      "negative\n",
      "3521.079999999998\n",
      "percentage: 100\n",
      "positive\n",
      "13704.0\n",
      "negative\n",
      "8754.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,101,4):\n",
    "    print(f'percentage: {i}')\n",
    "    print('positive')\n",
    "    print(np.percentile(train_df[train_df.labels == 1].contents.map(len), i))\n",
    "    print('negative')\n",
    "    print(np.percentile(train_df[train_df.labels == 0].contents.map(len), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21e679",
   "metadata": {},
   "source": [
    "###### Doesn't seem likely. We can see there is a little divergence when the comments start to get longer that people with good reviews will tend to write longer comments. #trustinhumanityrestored (not really)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe81516",
   "metadata": {},
   "source": [
    "### What about number of paragraphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c06ac233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_paragraph(x):\n",
    "    return x.count('<br /><br />') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe17f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = pd.concat([data.contents.apply(counter), data.labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4db9804f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the n parragraphs of model when positive:\n",
      "count    12500.000000\n",
      "mean         2.969360\n",
      "std          2.513859\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max         35.000000\n",
      "Name: contents, dtype: float64\n",
      "\n",
      "\n",
      "Describe the n parragraphs of model when negative:\n",
      "count    12500.000000\n",
      "mean         3.105440\n",
      "std          2.780399\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max         47.000000\n",
      "Name: contents, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Describe the n parragraphs of model when positive:')\n",
    "print(paragraphs[paragraphs.labels == 1].contents.describe())\n",
    "print('\\n')\n",
    "print('Describe the n parragraphs of model when negative:')\n",
    "print(paragraphs[paragraphs.labels == 0].contents.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6bb3e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage: 80\n",
      "positive\n",
      "5.0\n",
      "negative\n",
      "5.0\n",
      "percentage: 84\n",
      "positive\n",
      "5.0\n",
      "negative\n",
      "5.0\n",
      "percentage: 88\n",
      "positive\n",
      "6.0\n",
      "negative\n",
      "6.0\n",
      "percentage: 92\n",
      "positive\n",
      "7.0\n",
      "negative\n",
      "7.0\n",
      "percentage: 96\n",
      "positive\n",
      "8.0\n",
      "negative\n",
      "8.0\n",
      "percentage: 100\n",
      "positive\n",
      "35.0\n",
      "negative\n",
      "47.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,101,4):\n",
    "    print(f'percentage: {i}')\n",
    "    print('positive')\n",
    "    print(np.percentile(paragraphs[paragraphs.labels == 1].contents, i))\n",
    "    print('negative')\n",
    "    print(np.percentile(paragraphs[paragraphs.labels == 0].contents , i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34ba21",
   "metadata": {},
   "source": [
    "###### Doesn't seem likely.  There are cases that are super weird but nothing really there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93bd5f",
   "metadata": {},
   "source": [
    "### What about complexity and readiability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72805488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FleschReadabilityEase(text):\n",
    "    if len(text) > 0:\n",
    "        return 206.835 - (1.015 * len(text.split()) / len(text.split('.')) ) - 84.6 * (sum(list(map(lambda x: 1 if x in [\"a\",\"i\",\"e\",\"o\",\"u\",\"y\",\"A\",\"E\",\"I\",\"O\",\"U\",\"y\"] else 0,text))) / len(text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58751a6",
   "metadata": {},
   "source": [
    "###### Most common word for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d57b119",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>226374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>110239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>97692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>91327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>72318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>br</td>\n",
       "      <td>68495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it</td>\n",
       "      <td>65011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>62845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>this</td>\n",
       "      <td>50974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>that</td>\n",
       "      <td>49116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>was</td>\n",
       "      <td>32075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>as</td>\n",
       "      <td>31526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>29811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>movie</td>\n",
       "      <td>29732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>with</td>\n",
       "      <td>29532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>28659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>film</td>\n",
       "      <td>26875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>you</td>\n",
       "      <td>23086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>22838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>not</td>\n",
       "      <td>20462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     the  226374\n",
       "1     and  110239\n",
       "2      of   97692\n",
       "3      to   91327\n",
       "4      is   72318\n",
       "5      br   68495\n",
       "6      it   65011\n",
       "7      in   62845\n",
       "8    this   50974\n",
       "9    that   49116\n",
       "10    was   32075\n",
       "11     as   31526\n",
       "12    for   29811\n",
       "13  movie   29732\n",
       "14   with   29532\n",
       "15    but   28659\n",
       "16   film   26875\n",
       "17    you   23086\n",
       "18     on   22838\n",
       "19    not   20462"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Most common words in general\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'})\n",
    "list_of_words = cv.fit_transform(X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e007398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>116902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>60296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>51458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>45150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>38653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>33731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>br</td>\n",
       "      <td>33091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>32486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>23998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>23519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as</td>\n",
       "      <td>17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>with</td>\n",
       "      <td>15599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>15132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>was</td>\n",
       "      <td>14698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>film</td>\n",
       "      <td>14146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>14098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movie</td>\n",
       "      <td>12845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>his</td>\n",
       "      <td>11603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>11422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you</td>\n",
       "      <td>11294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     the  116902\n",
       "1     and   60296\n",
       "2      of   51458\n",
       "3      to   45150\n",
       "4      is   38653\n",
       "5      in   33731\n",
       "6      br   33091\n",
       "7      it   32486\n",
       "8    that   23998\n",
       "9    this   23519\n",
       "10     as   17752\n",
       "11   with   15599\n",
       "12    for   15132\n",
       "13    was   14698\n",
       "14   film   14146\n",
       "15    but   14098\n",
       "16  movie   12845\n",
       "17    his   11603\n",
       "18     on   11422\n",
       "19    you   11294"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_X_train = train_df.contents[train_df.labels == 1]\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,1))\n",
    "list_of_words = cv.fit_transform(pos_X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0736ff54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>116902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>60296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>51458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>45150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>38653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>33731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>br</td>\n",
       "      <td>33091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>32486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>23998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>23519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as</td>\n",
       "      <td>17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>with</td>\n",
       "      <td>15599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>15132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>was</td>\n",
       "      <td>14698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>film</td>\n",
       "      <td>14146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>14098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movie</td>\n",
       "      <td>12845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>his</td>\n",
       "      <td>11603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>11422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you</td>\n",
       "      <td>11294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     the  116902\n",
       "1     and   60296\n",
       "2      of   51458\n",
       "3      to   45150\n",
       "4      is   38653\n",
       "5      in   33731\n",
       "6      br   33091\n",
       "7      it   32486\n",
       "8    that   23998\n",
       "9    this   23519\n",
       "10     as   17752\n",
       "11   with   15599\n",
       "12    for   15132\n",
       "13    was   14698\n",
       "14   film   14146\n",
       "15    but   14098\n",
       "16  movie   12845\n",
       "17    his   11603\n",
       "18     on   11422\n",
       "19    you   11294"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_X_train = train_df.contents[train_df.labels == 0]\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'})\n",
    "list_of_words = cv.fit_transform(pos_X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75815e",
   "metadata": {},
   "source": [
    "#### 2) Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3e56711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>but</td>\n",
       "      <td>28659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>23086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not</td>\n",
       "      <td>20462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he</td>\n",
       "      <td>20282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all</td>\n",
       "      <td>16114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>at</td>\n",
       "      <td>15768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>they</td>\n",
       "      <td>15458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>by</td>\n",
       "      <td>15087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>an</td>\n",
       "      <td>14403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>who</td>\n",
       "      <td>14306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>so</td>\n",
       "      <td>13948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>from</td>\n",
       "      <td>13817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>like</td>\n",
       "      <td>13521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>there</td>\n",
       "      <td>12722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>her</td>\n",
       "      <td>12454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>or</td>\n",
       "      <td>12129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>just</td>\n",
       "      <td>11926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>about</td>\n",
       "      <td>11818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>out</td>\n",
       "      <td>11523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>if</td>\n",
       "      <td>11301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     but   28659\n",
       "1     you   23086\n",
       "2     not   20462\n",
       "3      he   20282\n",
       "4     all   16114\n",
       "5      at   15768\n",
       "6    they   15458\n",
       "7      by   15087\n",
       "8      an   14403\n",
       "9     who   14306\n",
       "10     so   13948\n",
       "11   from   13817\n",
       "12   like   13521\n",
       "13  there   12722\n",
       "14    her   12454\n",
       "15     or   12129\n",
       "16   just   11926\n",
       "17  about   11818\n",
       "18    out   11523\n",
       "19     if   11301"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = 'the and of to is in br it that this as with for was film movie his on are have be one'.split(' ')\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "list_of_words = cv.fit_transform(X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d71c93",
   "metadata": {},
   "source": [
    "### 2) Running the first models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a880f",
   "metadata": {},
   "source": [
    "#### Model number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07155c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 17.154719999999998\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a1d26",
   "metadata": {},
   "source": [
    "This is the base Multinominal only using basic stop words in english. It is using a basic ngram_range of 1,1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6e38d",
   "metadata": {},
   "source": [
    "#### Model number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4e570d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 2,991,762 \n",
      "The amount of time it took to vectorize was: 13.267948000000004\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3663  474]\n",
      " [ 545 3568]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8827313211281543\n",
      "Accuracy Score: 0.8764848484848485\n",
      "Recall Score: 0.8674933138828106\n",
      "f1 Score 0.8750459840588596\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eba6da",
   "metadata": {},
   "source": [
    "The second model performs better, specially in recall. However it takes too much time to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d499e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 2,441,663 \n",
      "The amount of time it took to vectorize was: 10.759179000000017\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3653  484]\n",
      " [ 550 3563]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4137\n",
      "           1       0.88      0.87      0.87      4113\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8804052384482333\n",
      "Accuracy Score: 0.8746666666666667\n",
      "Recall Score: 0.8662776562120107\n",
      "f1 Score 0.8732843137254902\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "X_train_sample = X_train.sample(frac=.8, random_state=50)\n",
    "y_train_sample = y_train.sample(frac=.8, random_state=50)\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train_sample, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train_sample)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b6fa3",
   "metadata": {},
   "source": [
    "Feeding the model with less amount of data; seems to make the model run worse, which was expected. I need to check with an a/b testing though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc5a1c",
   "metadata": {},
   "source": [
    "#### Model number 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "635a74ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 5,342,619 \n",
      "The amount of time it took to vectorize was: 21.06203400000001\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3643  494]\n",
      " [ 527 3586]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.878921568627451\n",
      "Accuracy Score: 0.8762424242424243\n",
      "Recall Score: 0.8718696814976903\n",
      "f1 Score 0.8753814231661174\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,5))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train_sample, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train_sample)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ecd56",
   "metadata": {},
   "source": [
    "#### Model number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e2ef4d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 16.878854000000004\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "stop_words = 'the and of to is in br it that this as with for was film movie his on are have be one'.split(' ')\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3))\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e4097",
   "metadata": {},
   "source": [
    "This was a mechanical way to extract words but I have an idea of how to authomate the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe20d32",
   "metadata": {},
   "source": [
    "### 3) Tweeking Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2071e",
   "metadata": {},
   "source": [
    "#### Max df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bc6d6",
   "metadata": {},
   "source": [
    "Max_df and min_df are use to eliminate words based on some threshold. The idea is that some tokens instead of helping\n",
    "the model are only noise.\n",
    "<br>There are two basic approaches to handle this types of words. We can eliminate very common words(using **max_df**) or we can eliminate very rare words using min_df.\n",
    "<br><br> The idea with max_df is that if a word appears at least in a certain percentage of the sample then it should be removed.\n",
    "<br><br> The idea with min_df is that if a word appears in less document that in the theshold it should be ignored. \n",
    "<br><br> Notice that max_df will have a lot of overlapping with stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4783ca4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 0.4\n",
      "(16750, 3713413)\n",
      "This is the shape for 0.5\n",
      "(16750, 3713428)\n",
      "This is the shape for 0.6\n",
      "(16750, 3713440)\n",
      "This is the shape for 0.7\n",
      "(16750, 3713446)\n",
      "This is the shape for 0.8\n",
      "(16750, 3713448)\n",
      "This is the shape for 0.9\n",
      "(16750, 3713452)\n",
      "This is the shape for 1.0\n",
      "(16750, 3713457)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,11,1):\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=i/10)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i/10}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9808131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 0.4\n",
      "(16750, 63655)\n",
      "This is the shape for 0.5\n",
      "(16750, 63670)\n",
      "This is the shape for 0.6\n",
      "(16750, 63680)\n",
      "This is the shape for 0.7\n",
      "(16750, 63685)\n",
      "This is the shape for 0.8\n",
      "(16750, 63687)\n",
      "This is the shape for 0.9\n",
      "(16750, 63691)\n",
      "This is the shape for 1.0\n",
      "(16750, 63696)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,11,1):\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,1), max_df=i/10)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i/10}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38a720",
   "metadata": {},
   "source": [
    "I don't see much of a difference in this max_df, even at really low percentages. But, never know if this can really affect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "851aa8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>character</td>\n",
       "      <td>4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>films</td>\n",
       "      <td>4627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>life</td>\n",
       "      <td>4399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where</td>\n",
       "      <td>4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plot</td>\n",
       "      <td>4349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>little</td>\n",
       "      <td>4309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>show</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>love</td>\n",
       "      <td>4287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>over</td>\n",
       "      <td>4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>best</td>\n",
       "      <td>4199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>did</td>\n",
       "      <td>4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>know</td>\n",
       "      <td>4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>does</td>\n",
       "      <td>4065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>off</td>\n",
       "      <td>4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ever</td>\n",
       "      <td>3982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>man</td>\n",
       "      <td>3980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>better</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>here</td>\n",
       "      <td>3884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>end</td>\n",
       "      <td>3807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>your</td>\n",
       "      <td>3794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  counts\n",
       "0   character    4746\n",
       "1       films    4627\n",
       "2        life    4399\n",
       "3       where    4350\n",
       "4        plot    4349\n",
       "5      little    4309\n",
       "6        show    4296\n",
       "7        love    4287\n",
       "8        over    4270\n",
       "9        best    4199\n",
       "10        did    4190\n",
       "11       know    4167\n",
       "12       does    4065\n",
       "13        off    4059\n",
       "14       ever    3982\n",
       "15        man    3980\n",
       "16     better    3936\n",
       "17       here    3884\n",
       "18        end    3807\n",
       "19       your    3794"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Most common words in general\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,1), max_df=.2)\n",
    "list_of_words = cv.fit_transform(X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c2100",
   "metadata": {},
   "source": [
    "#### Model number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca7d72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 18.143799\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=.2 )\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "803f4ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 17.942894000000024\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=.3)\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b73dd",
   "metadata": {},
   "source": [
    "This models perform quiet similar to the models that where run with the decided stop_words (which was expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3cd0d",
   "metadata": {},
   "source": [
    "#### Model number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddfe39c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 18.375955000000033\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "stop_words = 'the and of to is in br it that this as with for was film movie his on are have be one'.split(' ')\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), max_df=.3)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34387d",
   "metadata": {},
   "source": [
    "There was a lot of overlap, and this little amount of words really make a difference in the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f83cc",
   "metadata": {},
   "source": [
    "#### Models using min_df alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75874e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 38025)\n",
      "This is the shape for 5\n",
      "(16750, 22483)\n",
      "This is the shape for 10\n",
      "(16750, 14804)\n",
      "This is the shape for 15\n",
      "(16750, 11432)\n",
      "This is the shape for 20\n",
      "(16750, 9375)\n",
      "This is the shape for 25\n",
      "(16750, 7969)\n",
      "This is the shape for 30\n",
      "(16750, 7034)\n",
      "This is the shape for 50\n",
      "(16750, 4803)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,10,15,20,25,30,50]:\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,1), min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c819647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 622962)\n",
      "This is the shape for 5\n",
      "(16750, 175106)\n",
      "This is the shape for 10\n",
      "(16750, 80501)\n",
      "This is the shape for 15\n",
      "(16750, 52307)\n",
      "This is the shape for 20\n",
      "(16750, 38496)\n",
      "This is the shape for 25\n",
      "(16750, 30253)\n",
      "This is the shape for 30\n",
      "(16750, 24837)\n",
      "This is the shape for 50\n",
      "(16750, 14359)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,10,15,20,25,30,50]:\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8c3cff7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 408279)\n",
      "This is the shape for 5\n",
      "(16750, 99325)\n",
      "This is the shape for 10\n",
      "(16750, 43980)\n",
      "This is the shape for 15\n",
      "(16750, 28243)\n",
      "This is the shape for 20\n",
      "(16750, 20688)\n",
      "This is the shape for 25\n",
      "(16750, 16255)\n",
      "This is the shape for 30\n",
      "(16750, 13391)\n",
      "This is the shape for 50\n",
      "(16750, 7828)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,10,15,20,25,30,50]:\n",
    "    count_vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e0b08",
   "metadata": {},
   "source": [
    "#### Model number 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28c5b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 99,325 \n",
      "The amount of time it took to vectorize was: 11.592953999999963\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3639  498]\n",
      " [ 505 3608]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      4137\n",
      "           1       0.88      0.88      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8787140769605456\n",
      "Accuracy Score: 0.8784242424242424\n",
      "Recall Score: 0.8772185752492099\n",
      "f1 Score 0.8779656892566006\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), min_df=5)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5048d13",
   "metadata": {},
   "source": [
    "#### Model number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19a7983f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 43,980 \n",
      "The amount of time it took to vectorize was: 10.890859999999975\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3592  545]\n",
      " [ 510 3603]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      4137\n",
      "           1       0.87      0.88      0.87      4113\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8686113789778206\n",
      "Accuracy Score: 0.8721212121212121\n",
      "Recall Score: 0.8760029175784099\n",
      "f1 Score 0.8722914901343661\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), min_df=10)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e748d255",
   "metadata": {},
   "source": [
    "Lets try some mixture of both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca693001",
   "metadata": {},
   "source": [
    "#### Model number 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e6c60c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 80,433 \n",
      "The amount of time it took to vectorize was: 13.848969000000011\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3630  507]\n",
      " [ 445 3668]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4137\n",
      "           1       0.88      0.89      0.89      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.878562874251497\n",
      "Accuracy Score: 0.8846060606060606\n",
      "Recall Score: 0.8918064672988086\n",
      "f1 Score 0.8851351351351352\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=10, max_df=0.3)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2f446",
   "metadata": {},
   "source": [
    "#### Model number 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b09b3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 80,457 \n",
      "The amount of time it took to vectorize was: 13.599285000000009\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3628  509]\n",
      " [ 449 3664]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4137\n",
      "           1       0.88      0.89      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8780254013898874\n",
      "Accuracy Score: 0.8838787878787879\n",
      "Recall Score: 0.8908339411621687\n",
      "f1 Score 0.8843832971276853\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=10, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb10688",
   "metadata": {},
   "source": [
    "The combination of both doesn't look better (need more testing to check if it is the same) but it may be faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c1dde",
   "metadata": {},
   "source": [
    "#### Model number 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5db7ebc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 175,062 \n",
      "The amount of time it took to vectorize was: 13.904557000000068\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3661  476]\n",
      " [ 474 3639]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      4137\n",
      "           1       0.88      0.88      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.884325637910085\n",
      "Accuracy Score: 0.8848484848484849\n",
      "Recall Score: 0.8847556528081693\n",
      "f1 Score 0.8845405930967428\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=5, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1301727",
   "metadata": {},
   "source": [
    "#### Model number 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7af35965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 622,918 \n",
      "The amount of time it took to vectorize was: 15.014494000000013\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3704  433]\n",
      " [ 467 3646]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4137\n",
      "           1       0.89      0.89      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8938465310125031\n",
      "Accuracy Score: 0.8909090909090909\n",
      "Recall Score: 0.886457573547289\n",
      "f1 Score 0.89013671875\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=2, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530642cd",
   "metadata": {},
   "source": [
    "I would like to understand exactly why when you start to increase the min_df you get a worse score if also you are working with a max_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959686cc",
   "metadata": {},
   "source": [
    "### 3.5) Tailored based stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8cc68b",
   "metadata": {},
   "source": [
    "### 4) Contrasting Models and A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b606db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is another Christian propaganda fil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman who hates cats (Alice Krige) and her s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beast Wars is a show that is over-hyped, overp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An excellent example of \"cowboy noir\", as it's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok, basically this is a popcorn sci-fi movie, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Jimmy Cagney races by your eyes constantly in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Very much a film from the times -- extremely l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>The Little Mermaid is one of my absolute favor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>With a simplistic story and an engaging heroin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The 63 year reign of Queen Victoria is perhaps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                contents  labels\n",
       "0      This movie is another Christian propaganda fil...       0\n",
       "1      A woman who hates cats (Alice Krige) and her s...       1\n",
       "2      Beast Wars is a show that is over-hyped, overp...       0\n",
       "3      An excellent example of \"cowboy noir\", as it's...       1\n",
       "4      Ok, basically this is a popcorn sci-fi movie, ...       1\n",
       "...                                                  ...     ...\n",
       "24995  Jimmy Cagney races by your eyes constantly in ...       1\n",
       "24996  Very much a film from the times -- extremely l...       0\n",
       "24997  The Little Mermaid is one of my absolute favor...       0\n",
       "24998  With a simplistic story and an engaging heroin...       1\n",
       "24999  The 63 year reign of Queen Victoria is perhaps...       1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83f69a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "for i1,i2 in kf.split(data):\n",
    "    lst1 = list(i1)\n",
    "    lst2 = list(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa6687d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=2, max_df=0.4)\n",
    "X = 1\n",
    "y = 1\n",
    "test_split = 1\n",
    "\n",
    "def model_run(cv, clf, model_name, X, y, test_split):\n",
    "    for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "        # Vectorization\n",
    "        start = time.process_time()\n",
    "        X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "        print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "        print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "\n",
    "        # Running the model\n",
    "        print(clf_name)\n",
    "        clf.fit(X_train_vectorized, y_train)\n",
    "        check_model(clf, X_test_vectorized, y_test)\n",
    "        print(\"_________________________________________________\")\n",
    "        \n",
    "def get_test_split():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "014b6dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12500</th>\n",
       "      <td>argh! this film hurts my head. and not in a go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12501</th>\n",
       "      <td>Istanbul is another one of those expatriate fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12502</th>\n",
       "      <td>As a history nut who is particularly intereste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12503</th>\n",
       "      <td>This is a very enjoyable film with excellent a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504</th>\n",
       "      <td>Me being of Irish origins, loved this movie, N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Jimmy Cagney races by your eyes constantly in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Very much a film from the times -- extremely l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>The Little Mermaid is one of my absolute favor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>With a simplistic story and an engaging heroin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The 63 year reign of Queen Victoria is perhaps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                contents  labels\n",
       "12500  argh! this film hurts my head. and not in a go...       0\n",
       "12501  Istanbul is another one of those expatriate fi...       0\n",
       "12502  As a history nut who is particularly intereste...       0\n",
       "12503  This is a very enjoyable film with excellent a...       1\n",
       "12504  Me being of Irish origins, loved this movie, N...       1\n",
       "...                                                  ...     ...\n",
       "24995  Jimmy Cagney races by your eyes constantly in ...       1\n",
       "24996  Very much a film from the times -- extremely l...       0\n",
       "24997  The Little Mermaid is one of my absolute favor...       0\n",
       "24998  With a simplistic story and an engaging heroin...       1\n",
       "24999  The 63 year reign of Queen Victoria is perhaps...       1\n",
       "\n",
       "[12500 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[~data.index.isin(i1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
