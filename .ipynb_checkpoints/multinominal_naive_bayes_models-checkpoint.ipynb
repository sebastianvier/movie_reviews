{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7cd9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python in build modules:\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "## EDA libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "## Metrics (sklearn)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "## Models (sklearn)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ef8b2",
   "metadata": {},
   "source": [
    "### 1) Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd00805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "## Importing the data\n",
    "\n",
    "path = 'data/train/'\n",
    "\n",
    "count = 0\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "for label in ['neg','pos']:\n",
    "    filenames = os.listdir(path + label)\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        with open(os.path.join(path, label, filename), 'r') as f:\n",
    "            labels.append(1 if label == 'pos' else 0) # 1 is positve 0 is negative\n",
    "            contents.append(f.read())\n",
    "print(count)\n",
    "            \n",
    "data = pd.DataFrame({\n",
    "    'contents' : contents,\n",
    "    'labels': labels,\n",
    "\n",
    "})\n",
    "\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True) # This code will shuffle the data (just in case!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b82a82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first episode of this new show was on today, and it was horrible. Not only did Shaggy have a squeaky new voice that made listening to his lines torture, but it's so far away from the original concept and animation style that it's barely recognizable as a 'Scooby-Doo' show.<br /><br />Even back in the dark days when Fred and Velma were gone and Scooby's nephew Scrappy was there, the team still solved mysteries. This new show instead features Shaggy and Scooby battling a James Bond type super-villain and his henchmen while living in a mansion. There's not even a van called 'The Mystery Machine' (and the teaser for the next episode which promised a transformers type robot car did NOT put my mind at ease). How can anyone take Scooby Doo and make THIS? <br /><br />The show earns two point for two scenes featuring the whole Scooby Doo gang, all of whom speak with the correct voices except Shaggy, and even then I'm being far too generous.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sample = data.sample()\n",
    "print(sample.contents.iloc[0])\n",
    "print(sample.labels.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdecdb1c",
   "metadata": {},
   "source": [
    "#### Just to be clear negative is 0 and positive is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1935c7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab00242",
   "metadata": {},
   "source": [
    "Ok, the data is **completely balanced**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298663a9",
   "metadata": {},
   "source": [
    " ###### At this moment we are going to see 5 examples of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b3dd8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "\n",
      "\n",
      "Realistic movie,sure,except for the fact that the characters don't look like to be scared. When Billy Zane tries to kill someone, he feels bad...but he doesn't look like to. That's why I don't like his performance in this movie. Tom Berenger is again playing a soldier. No good thrill, realistic sequences. Not always shooting, that is one great thing. Well filmed. I hate the helicopter sequence, cause only one terrorist kills almost the whole marine bunch...I give it **and a half out of *****\n",
      "\n",
      "\n",
      "this movie was banned in england? why? tom savini, george romero, dario argento, lucio fulci and others had done far worse before and have continued to so since...<br /><br />this movie has all the basic elements of a decent 70s or early 80's horror film. good looking girls (who can't act to save their lives, by the way), a terrible lightning storm with a torrential downpour, a scythe, a crazy brother wandering around the family estate, and actually a pretty damn good twist at the end. but banned? seriously. when the English parliament banned this movie, the italians probably laughed their collective asses off at how backwards and prudish the brits really were.<br /><br />there was maybe two minutes of total screen time devoted to the violence and gore (which was greatly underdone). there was nudity but no sex although allusions to sex were made, obviously. but absolutely nothing worthy of being banned.<br /><br />i would like to see what could have been done if the filmmakers had a decent budget to work with. as it stands, the film is entertaining, but the lack of picture and sound quality take away from the end result.<br /><br />banned... what a joke...\n",
      "\n",
      "\n",
      "positive\n",
      "\n",
      "\n",
      "Even longtime Shirley fans may be surprised by \"Now and Forever.\" The movie was filmed with Paramount studios  not with Shirley's parent company Twentieth Century Fox  in 1934, before Fox producer Darryl Zanuck had perfected the successful Shirley formula (cute songs, cold hearts for her to melt, young couples for her to play cupid to, happy endings). Thus \"Now and Forever\" falls into the category of a Shirley vehicle without the standard Shirley story. It is an awkward position for any movie, but this impressive, talented cast makes it work.<br /><br />Gary Cooper and Carole Lombard star as fun-loving, irresponsible con artists Jerry and Toni Day. The only thing that this devoted yet dysfunctional duo seems to hate more than being together is being apart. When they are suddenly landed with custody of Jerry's young daughter Penny (Shirley Temple), it is Toni  and not Penny, as many believe  who persuades Jerry to give up his criminal career. But Jerry flounders at his desk job, and desperate to prove that he can provide for his new family, he soon returns to thieving and dishonesty. In a standard Shirley device, Penny tries to melt the heart of crusty curmudgeon Felix Evans, the victim of one of Jerry's cons, but her attempt fails, for Evans is revealed to be a con artist himself, and he blackmails Jerry into helping him steal jewels. The drama, gunfight, death, and sorrow that follow all make this film a very unusual one for Little Miss Sunshine. There is no happy ending, no dancing, and only one song sequence (the cute number \"The World Owes Me a Living\").<br /><br />But this does not mean that Shirley fans should avoid \"Now and Forever.\" Rather, it's divergence from the usual Shirley story make it more interesting and memorable than many of her other films. But beware: You should avoid colorized version of this film, and see it in black-and-white if you can. The color is bright, garish, and unrealistic, and in many scenes, Shirley's famous curls are actually red instead of blonde. Yikes!\n",
      "\n",
      "\n",
      "Matthew McConaughey is a mysterious man waiting for Agent Wesley Doyle (Powers Boothe) in his FBI office. He claims to have information about a serial killer chased by FBI. When Agent Doyle arrives in the office, he tells him that the serial killer is indeed his dead brother. Agent Doyle requests some evidence, and the man tells the story of his life, since his childhood. They were a simple family of three: his widow father Meiks (Bill Paxton), his brother and himself. One night, his father gathers the two brothers and tells them that an angel of God had just visited him and assigned his family to destroy demons. What happens next is one of the most scary movie I have ever seen. <br /><br />I watched this movie four months ago on VHS, and yesterday I watched again, now on DVD. Although being a low-budget movie, the screenplay is sharp, with no flaw. The cast is outstanding, but I would like to highlight the performance of Matt O'Leary as the young Felton. It is a very difficult and complex role to be performed by a young teenager. The direction of Bill Paxton is remarkable. There is no explicit violence in this horror movie. A great debut behind the camera. I regret the Brazilian title of this movie: 'A Mão do Diabo' (The Devil's Hand'). If at least it were 'The God's Hand', it might be acceptable. But calling this movie as 'the devil's hand' is indeed ridiculous. Brent Hanley, the screenwriter, did not deserve such a lack of respect from the Brazilian distributor. This film is highly recommended. My vote is eight.<br /><br />Title (Brazil): \"A Mão do Diabo\" (\"The Devil's Hand\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in data.labels.unique():\n",
    "    print(\"negative\" if label ==  0 else \"positive\")\n",
    "    print(\"\\n\")\n",
    "    for content in data.contents[data.labels == label].sample(2):\n",
    "        print(content)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2f5d0",
   "metadata": {},
   "source": [
    "###### From now on I am going to be using the training data to explore the data so I can get some conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99e48b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.contents\n",
    "y = data.labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54397f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "932d5564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4137\n",
       "1    4113\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edfbbc31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8387\n",
       "0    8363\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.labels.value_counts() # Just checking the proportions haven't change much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9304e8",
   "metadata": {},
   "source": [
    "### Does it has to do something with length?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034f50c",
   "metadata": {},
   "source": [
    "###### Mean of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfb077e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of all reviews: 1328.28\n",
      "Mean length in positive reviews: 1352.3945391677596\n",
      "Mean length in negative reviews: 1304.1033122085375\n",
      "Ratio positive: 1.0181547107294844\n",
      "Ration negative: 0.9817985004731966\n"
     ]
    }
   ],
   "source": [
    "mean_length_full = np.round(X_train.map(len).mean(),2)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "mean_lenght_pos = train_df[train_df.labels == 1].contents.map(len).mean()\n",
    "mean_length_neg = train_df[train_df.labels == 0].contents.map(len).mean()\n",
    "ratio_pos =  mean_lenght_pos / mean_length_full\n",
    "ratio_neg =  mean_length_neg / mean_length_full\n",
    "\n",
    "print(f'Mean length of all reviews: {mean_length_full}')\n",
    "print(f'Mean length in positive reviews: {mean_lenght_pos}')\n",
    "print(f'Mean length in negative reviews: {mean_length_neg}')\n",
    "print(f'Ratio positive: {ratio_pos}')\n",
    "print(f'Ration negative: {ratio_neg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab09761e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16750.000000\n",
       "mean      1328.283522\n",
       "std       1009.709272\n",
       "min         53.000000\n",
       "25%        702.250000\n",
       "50%        981.000000\n",
       "75%       1612.000000\n",
       "max      13704.000000\n",
       "Name: contents, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.map(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd11a0",
   "metadata": {},
   "source": [
    "We can run an **A/B test** here, but there is an indication that the **length** of the commentary has **nothing to do** with the idea if it is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587a175",
   "metadata": {},
   "source": [
    "###### Describing of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c84568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the length of model when positive:\n",
      "count     8387.000000\n",
      "mean      1352.394539\n",
      "std       1053.673512\n",
      "min         70.000000\n",
      "25%        695.000000\n",
      "50%        982.000000\n",
      "75%       1659.500000\n",
      "max      13704.000000\n",
      "Name: contents, dtype: float64\n",
      "\n",
      "\n",
      "Describe the length of model when negative:\n",
      "count    8363.000000\n",
      "mean     1304.103312\n",
      "std       963.063593\n",
      "min        53.000000\n",
      "25%       710.000000\n",
      "50%       981.000000\n",
      "75%      1554.000000\n",
      "max      8754.000000\n",
      "Name: contents, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Describe the length of model when positive:')\n",
    "print(train_df[train_df.labels == 1].contents.map(len).describe())\n",
    "print('\\n')\n",
    "print('Describe the length of model when negative:')\n",
    "print(train_df[train_df.labels == 0].contents.map(len).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e50f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage: 80\n",
      "positive\n",
      "1917.0\n",
      "negative\n",
      "1799.0\n",
      "percentage: 84\n",
      "positive\n",
      "2168.7199999999993\n",
      "negative\n",
      "2015.0\n",
      "percentage: 88\n",
      "positive\n",
      "2514.0\n",
      "negative\n",
      "2328.120000000001\n",
      "percentage: 92\n",
      "positive\n",
      "3005.0\n",
      "negative\n",
      "2755.12\n",
      "percentage: 96\n",
      "positive\n",
      "3815.119999999999\n",
      "negative\n",
      "3521.079999999998\n",
      "percentage: 100\n",
      "positive\n",
      "13704.0\n",
      "negative\n",
      "8754.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,101,4):\n",
    "    print(f'percentage: {i}')\n",
    "    print('positive')\n",
    "    print(np.percentile(train_df[train_df.labels == 1].contents.map(len), i))\n",
    "    print('negative')\n",
    "    print(np.percentile(train_df[train_df.labels == 0].contents.map(len), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21e679",
   "metadata": {},
   "source": [
    "###### Doesn't seem likely. We can see there is a little divergence when the comments start to get longer that people with good reviews will tend to write longer comments. #trustinhumanityrestored (not really)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe81516",
   "metadata": {},
   "source": [
    "### What about number of paragraphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c06ac233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_paragraph(x):\n",
    "    return x.count('<br /><br />') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe17f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = pd.concat([train_df.contents.apply(count_paragraph), train_df.labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51289f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 9.5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(6,5))\n",
    "axs = sns.countplot(data=paragraphs[paragraphs.labels == 1], x='contents')\n",
    "axs.set_xlim(-1,9.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd4b5ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianvier/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='contents', ylabel='count'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplotfig, axs = plt.subplots(1,1, figsize=(6,5))\n",
    "axs = sns.countplot(data=paragraphs, x='contents')\n",
    "axs.set_xlim(-1,9.5)(paragraphs[paragraphs.labels == 1].contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db9804f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the n parragraphs of model when positive:\n",
      "count    8387.000000\n",
      "mean        2.972696\n",
      "std         2.518918\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         4.000000\n",
      "max        26.000000\n",
      "Name: contents, dtype: float64\n",
      "\n",
      "\n",
      "Describe the n parragraphs of model when negative:\n",
      "count    8363.000000\n",
      "mean        3.116705\n",
      "std         2.797950\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         4.000000\n",
      "max        47.000000\n",
      "Name: contents, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Describe the n parragraphs of model when positive:')\n",
    "print(paragraphs[paragraphs.labels == 1].contents.describe())\n",
    "print('\\n')\n",
    "print('Describe the n parragraphs of model when negative:')\n",
    "print(paragraphs[paragraphs.labels == 0].contents.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bb3e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage: 80\n",
      "positive\n",
      "5.0\n",
      "negative\n",
      "5.0\n",
      "percentage: 84\n",
      "positive\n",
      "5.0\n",
      "negative\n",
      "5.0\n",
      "percentage: 88\n",
      "positive\n",
      "6.0\n",
      "negative\n",
      "6.0\n",
      "percentage: 92\n",
      "positive\n",
      "7.0\n",
      "negative\n",
      "7.0\n",
      "percentage: 96\n",
      "positive\n",
      "8.0\n",
      "negative\n",
      "8.0\n",
      "percentage: 100\n",
      "positive\n",
      "26.0\n",
      "negative\n",
      "47.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,101,4):\n",
    "    print(f'percentage: {i}')\n",
    "    print('positive')\n",
    "    print(np.percentile(paragraphs[paragraphs.labels == 1].contents, i))\n",
    "    print('negative')\n",
    "    print(np.percentile(paragraphs[paragraphs.labels == 0].contents , i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34ba21",
   "metadata": {},
   "source": [
    "###### Doesn't seem likely.  There are cases that are outliers but nothing really there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8f4bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can actually look for the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93bd5f",
   "metadata": {},
   "source": [
    "### What about complexity and readiability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f47e3",
   "metadata": {},
   "source": [
    "###### Flesch ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "72805488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flesch_readability_ease(text):\n",
    "    if len(text) > 0:\n",
    "        text = text.replace(\"?\", \".\")\n",
    "        total_words = len(text.split())\n",
    "        total_sentences = len(text.split('.'))\n",
    "        total_sillables = sum(list(map(lambda x: 1 if x in [\"a\",\"i\",\"e\",\"o\",\"u\",\"y\",\"A\",\"E\",\"I\",\"O\",\"U\",\"y\"] else 0, text)))\n",
    "        return 206.835 - (1.015 *  total_words/ total_sentences) - 84.6 * (total_sillables / total_words)\n",
    "    \n",
    "def remove_outliers(X, y , function):\n",
    "    boolean = X.apply(function) > 0\n",
    "    return X[boolean],y[boolean]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbed9ff",
   "metadata": {},
   "source": [
    "It is not that easy, because there are times where you have ? or ! instead of a . And then you may have multiple !? or ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9812f20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dfd'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'df!'.replace('!', \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5210724",
   "metadata": {},
   "outputs": [],
   "source": [
    "flesch_ease = train_df.contents.map(FleschReadabilityEase)\n",
    "flesch_ease = pd.concat([train_df, flesch_ease], axis=1)\n",
    "flesch_ease.columns = ['contents', 'labels', 'ease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb1b1324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the ease of model when positive:\n",
      "count    8387.000000\n",
      "mean       38.949473\n",
      "std        14.656158\n",
      "min      -134.725000\n",
      "25%        30.794855\n",
      "50%        39.755331\n",
      "75%        48.474976\n",
      "max        85.408412\n",
      "Name: ease, dtype: float64\n",
      "\n",
      "\n",
      "Describe the ease of model when negative:\n",
      "count    8363.000000\n",
      "mean       41.710220\n",
      "std        16.602777\n",
      "min      -337.909000\n",
      "25%        34.047744\n",
      "50%        42.679525\n",
      "75%        51.194469\n",
      "max       103.367105\n",
      "Name: ease, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Describe the ease of model when positive:')\n",
    "print(flesch_ease[flesch_ease.labels == 1].ease.describe())\n",
    "print('\\n')\n",
    "print('Describe the ease of model when negative:')\n",
    "print(flesch_ease[flesch_ease.labels == 0].ease.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af616585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage: 80\n",
      "positive\n",
      "50.54745520133298\n",
      "negative\n",
      "53.188188158577596\n",
      "percentage: 84\n",
      "positive\n",
      "52.426362848962086\n",
      "negative\n",
      "55.0011225702047\n",
      "percentage: 88\n",
      "positive\n",
      "54.443156091257045\n",
      "negative\n",
      "56.96770877192985\n",
      "percentage: 92\n",
      "positive\n",
      "57.18548441708349\n",
      "negative\n",
      "59.651001063020445\n",
      "percentage: 96\n",
      "positive\n",
      "61.48505739004381\n",
      "negative\n",
      "63.615432606322905\n",
      "percentage: 100\n",
      "positive\n",
      "85.4084121621622\n",
      "negative\n",
      "103.36710526315791\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,101,4):\n",
    "    print(f'percentage: {i}')\n",
    "    print('positive')\n",
    "    print(np.percentile(flesch_ease[flesch_ease.labels == 1].ease, i))\n",
    "    print('negative')\n",
    "    print(np.percentile(flesch_ease[flesch_ease.labels == 0].ease, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11019b",
   "metadata": {},
   "source": [
    "###### The difference in complexity is not crazy, but is there (at least for this model) . Can we use this knowledge in some sort of way? The process is also a little bit memory consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cab672",
   "metadata": {},
   "source": [
    "##### There are outliers also outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "697e4e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This, the finest achievement from Georg Wilhelm Pabst\\'s Social Realism period is based upon a tragedy in early 1906 that claimed the lives of nearly 1100 French miners as a coal dust explosion deep in mines at Courrieres in northern France took place after a fire had smouldered for three weeks, eventually releasing deadly pit gas that brought about the fatalities. Estimable designer Erno Metzner creates stark sets that simulate the tragedy, providing a perception of reality, augmented by matchless sound editing, with the only music being produced by integral orchestras during the beginning and ending portions of a work for which aural effects possess equal importance with the eminent director\\'s fascinating visual compositions. Pabst\\'s manner of \"invisible editing\" that segues action from shot to shot through movements of players proves to be smoothly integrated within this landmark film that also showcases sublime cinematography utilizing cameras mounted upon vehicles, enabling the director to shift amid scenes without having a necessity of cutting. Although the work\\'s cardinal theme relates to Socialist dogma, the unforgettable power of this film is held in its details, born of Pabst\\'s nonpareil skill at weaving numerous plot lines into a cinema tapestry that stirs one to admiration for German rescue squads of whom their Fatherland is greatly proud while no less despairing of disastrous losses to the families of French victims; certainly, a seminal triumph fully as stimulating today to a cineaste as it was at the time of its first release.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Outliers of low understandability\n",
    "flesch_ease[flesch_ease.ease < -0].contents.sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a58c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are reviews that make little sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ef8cc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flesch_ease[flesch_ease.ease < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f905b021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i just saw this movie on TV..<br /><br />i've lost my dad when i was young and this movie surely did touch me..<br /><br />i can feel the lost that the little girl Desi felt..<br /><br />the feeling of wanting to see her father again..<br /><br />wanting to talk to him..<br /><br />or at least given the chance to say goodbye..<br /><br />and i'm so touched with the letter that was wrote back to her..<br /><br />saying that her father read her letter, and sent it back to someone to reply her and buy her a present because there isn't a shop in heaven..<br /><br />it just lets me feel that miracles do exist..\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Outliers of high understandability\n",
    "flesch_ease[flesch_ease.ease > 80].contents.sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb7428fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flesch_ease[flesch_ease.ease > 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2be9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>labels</th>\n",
       "      <th>ease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12131</th>\n",
       "      <td>Ernst Lubitsch's contribution to the American ...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.428436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12827</th>\n",
       "      <td>The name (Frau) of the main character is the G...</td>\n",
       "      <td>0</td>\n",
       "      <td>40.173923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>Upon The Straight Story release in 1999, it wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>34.813930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13762</th>\n",
       "      <td>This documentary explores a story covered in P...</td>\n",
       "      <td>1</td>\n",
       "      <td>23.340646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>Tho 35 years old, Groove Tube looks a lot like...</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.854812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>Yes, Kazaam is one of those horribly bad movie...</td>\n",
       "      <td>0</td>\n",
       "      <td>35.520517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>The 3rd and in my view the best of the Blackad...</td>\n",
       "      <td>1</td>\n",
       "      <td>39.070429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>!!!!! POSSIBLE SPOILER !!!!!&lt;br /&gt;&lt;br /&gt;You`d ...</td>\n",
       "      <td>0</td>\n",
       "      <td>29.169732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>I cant understand at all why so many Godzilla ...</td>\n",
       "      <td>0</td>\n",
       "      <td>25.185830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>This movie is just plain silly. Almost every s...</td>\n",
       "      <td>1</td>\n",
       "      <td>61.992981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16750 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                contents  labels       ease\n",
       "12131  Ernst Lubitsch's contribution to the American ...       1  40.428436\n",
       "12827  The name (Frau) of the main character is the G...       0  40.173923\n",
       "2912   Upon The Straight Story release in 1999, it wa...       1  34.813930\n",
       "13762  This documentary explores a story covered in P...       1  23.340646\n",
       "6369   Tho 35 years old, Groove Tube looks a lot like...       1  -3.854812\n",
       "...                                                  ...     ...        ...\n",
       "21575  Yes, Kazaam is one of those horribly bad movie...       0  35.520517\n",
       "5390   The 3rd and in my view the best of the Blackad...       1  39.070429\n",
       "860    !!!!! POSSIBLE SPOILER !!!!!<br /><br />You`d ...       0  29.169732\n",
       "15795  I cant understand at all why so many Godzilla ...       0  25.185830\n",
       "23654  This movie is just plain silly. Almost every s...       1  61.992981\n",
       "\n",
       "[16750 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flesch_ease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a5d12",
   "metadata": {},
   "source": [
    "###### So how is the data distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e0cc037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=\"labels\", y=\"ease\",\n",
    "                    data=flesch_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ad539cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=\"labels\", y=\"ease\",\n",
    "                    data=flesch_ease[flesch_ease.ease > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71263b00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=\"labels\", y=\"ease\",\n",
    "                    data=flesch_ease[flesch_ease.ease > 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35979931",
   "metadata": {},
   "source": [
    "###### There is a difference but not that much, when you take outliers positive reviews are just a bit harder to read. At least in this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58751a6",
   "metadata": {},
   "source": [
    "###### Most common word for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d57b119",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>226374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>110239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>97692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>91327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>72318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>br</td>\n",
       "      <td>68495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it</td>\n",
       "      <td>65011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>62845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>this</td>\n",
       "      <td>50974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>that</td>\n",
       "      <td>49116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>was</td>\n",
       "      <td>32075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>as</td>\n",
       "      <td>31526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>29811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>movie</td>\n",
       "      <td>29732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>with</td>\n",
       "      <td>29532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>28659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>film</td>\n",
       "      <td>26875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>you</td>\n",
       "      <td>23086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>22838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>not</td>\n",
       "      <td>20462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     the  226374\n",
       "1     and  110239\n",
       "2      of   97692\n",
       "3      to   91327\n",
       "4      is   72318\n",
       "5      br   68495\n",
       "6      it   65011\n",
       "7      in   62845\n",
       "8    this   50974\n",
       "9    that   49116\n",
       "10    was   32075\n",
       "11     as   31526\n",
       "12    for   29811\n",
       "13  movie   29732\n",
       "14   with   29532\n",
       "15    but   28659\n",
       "16   film   26875\n",
       "17    you   23086\n",
       "18     on   22838\n",
       "19    not   20462"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Most common words in general\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'})\n",
    "list_of_words = cv.fit_transform(X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e007398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>116902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>60296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>51458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>45150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>38653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>33731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>br</td>\n",
       "      <td>33091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>32486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>23998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>23519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as</td>\n",
       "      <td>17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>with</td>\n",
       "      <td>15599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>15132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>was</td>\n",
       "      <td>14698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>film</td>\n",
       "      <td>14146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>14098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movie</td>\n",
       "      <td>12845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>his</td>\n",
       "      <td>11603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>11422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you</td>\n",
       "      <td>11294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     the  116902\n",
       "1     and   60296\n",
       "2      of   51458\n",
       "3      to   45150\n",
       "4      is   38653\n",
       "5      in   33731\n",
       "6      br   33091\n",
       "7      it   32486\n",
       "8    that   23998\n",
       "9    this   23519\n",
       "10     as   17752\n",
       "11   with   15599\n",
       "12    for   15132\n",
       "13    was   14698\n",
       "14   film   14146\n",
       "15    but   14098\n",
       "16  movie   12845\n",
       "17    his   11603\n",
       "18     on   11422\n",
       "19    you   11294"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_X_train = train_df.contents[train_df.labels == 1]\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,1))\n",
    "list_of_words = cv.fit_transform(pos_X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0736ff54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>116902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>60296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>51458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>45150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>38653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>33731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>br</td>\n",
       "      <td>33091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>32486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>23998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>23519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as</td>\n",
       "      <td>17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>with</td>\n",
       "      <td>15599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>15132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>was</td>\n",
       "      <td>14698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>film</td>\n",
       "      <td>14146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>14098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movie</td>\n",
       "      <td>12845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>his</td>\n",
       "      <td>11603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>11422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you</td>\n",
       "      <td>11294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     the  116902\n",
       "1     and   60296\n",
       "2      of   51458\n",
       "3      to   45150\n",
       "4      is   38653\n",
       "5      in   33731\n",
       "6      br   33091\n",
       "7      it   32486\n",
       "8    that   23998\n",
       "9    this   23519\n",
       "10     as   17752\n",
       "11   with   15599\n",
       "12    for   15132\n",
       "13    was   14698\n",
       "14   film   14146\n",
       "15    but   14098\n",
       "16  movie   12845\n",
       "17    his   11603\n",
       "18     on   11422\n",
       "19    you   11294"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_X_train = train_df.contents[train_df.labels == 0]\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'})\n",
    "list_of_words = cv.fit_transform(pos_X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75815e",
   "metadata": {},
   "source": [
    "#### 2) Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a3e56711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films</td>\n",
       "      <td>2526</td>\n",
       "      <td>films</td>\n",
       "      <td>2526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>character</td>\n",
       "      <td>2386</td>\n",
       "      <td>character</td>\n",
       "      <td>2386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movies</td>\n",
       "      <td>2382</td>\n",
       "      <td>movies</td>\n",
       "      <td>2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>characters</td>\n",
       "      <td>2341</td>\n",
       "      <td>characters</td>\n",
       "      <td>2341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man</td>\n",
       "      <td>2330</td>\n",
       "      <td>man</td>\n",
       "      <td>2330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>then</td>\n",
       "      <td>2308</td>\n",
       "      <td>then</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>show</td>\n",
       "      <td>2308</td>\n",
       "      <td>show</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>little</td>\n",
       "      <td>2182</td>\n",
       "      <td>little</td>\n",
       "      <td>2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>where</td>\n",
       "      <td>2174</td>\n",
       "      <td>where</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>could</td>\n",
       "      <td>2152</td>\n",
       "      <td>could</td>\n",
       "      <td>2152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>being</td>\n",
       "      <td>2150</td>\n",
       "      <td>being</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>does</td>\n",
       "      <td>2106</td>\n",
       "      <td>does</td>\n",
       "      <td>2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>any</td>\n",
       "      <td>2026</td>\n",
       "      <td>any</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>over</td>\n",
       "      <td>2012</td>\n",
       "      <td>over</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>while</td>\n",
       "      <td>1944</td>\n",
       "      <td>while</td>\n",
       "      <td>1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>know</td>\n",
       "      <td>1917</td>\n",
       "      <td>know</td>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>here</td>\n",
       "      <td>1869</td>\n",
       "      <td>here</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>did</td>\n",
       "      <td>1850</td>\n",
       "      <td>did</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>these</td>\n",
       "      <td>1847</td>\n",
       "      <td>these</td>\n",
       "      <td>1847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>years</td>\n",
       "      <td>1830</td>\n",
       "      <td>years</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         words  counts       words  counts\n",
       "0        films    2526       films    2526\n",
       "1    character    2386   character    2386\n",
       "2       movies    2382      movies    2382\n",
       "3   characters    2341  characters    2341\n",
       "4          man    2330         man    2330\n",
       "5         then    2308        then    2308\n",
       "6         show    2308        show    2308\n",
       "7       little    2182      little    2182\n",
       "8        where    2174       where    2174\n",
       "9        could    2152       could    2152\n",
       "10       being    2150       being    2150\n",
       "11        does    2106        does    2106\n",
       "12         any    2026         any    2026\n",
       "13        over    2012        over    2012\n",
       "14       while    1944       while    1944\n",
       "15        know    1917        know    1917\n",
       "16        here    1869        here    1869\n",
       "17         did    1850         did    1850\n",
       "18       these    1847       these    1847\n",
       "19       years    1830       years    1830"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_X_train = train_df.contents[train_df.labels == 0]\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'}, max_df=.2)\n",
    "list_of_words = cv.fit_transform(pos_X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "df1 = pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "pos_X_train = train_df.contents[train_df.labels == 1]\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'}, max_df=.2)\n",
    "list_of_words = cv.fit_transform(pos_X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "df2 = pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})\n",
    "\n",
    "pd.concat([df1,df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d71c93",
   "metadata": {},
   "source": [
    "### 2) Running the first models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a880f",
   "metadata": {},
   "source": [
    "#### Model number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07155c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 17.154719999999998\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a1d26",
   "metadata": {},
   "source": [
    "This is the base Multinominal only using basic stop words in english. It is using a basic ngram_range of 1,1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6e38d",
   "metadata": {},
   "source": [
    "#### Model number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4e570d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 2,991,762 \n",
      "The amount of time it took to vectorize was: 13.267948000000004\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3663  474]\n",
      " [ 545 3568]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8827313211281543\n",
      "Accuracy Score: 0.8764848484848485\n",
      "Recall Score: 0.8674933138828106\n",
      "f1 Score 0.8750459840588596\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eba6da",
   "metadata": {},
   "source": [
    "The second model performs better, specially in recall. However it takes too much time to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d499e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 2,441,663 \n",
      "The amount of time it took to vectorize was: 10.759179000000017\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3653  484]\n",
      " [ 550 3563]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4137\n",
      "           1       0.88      0.87      0.87      4113\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8804052384482333\n",
      "Accuracy Score: 0.8746666666666667\n",
      "Recall Score: 0.8662776562120107\n",
      "f1 Score 0.8732843137254902\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "X_train_sample = X_train.sample(frac=.8, random_state=50)\n",
    "y_train_sample = y_train.sample(frac=.8, random_state=50)\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train_sample, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train_sample)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b6fa3",
   "metadata": {},
   "source": [
    "Feeding the model with less amount of data; seems to make the model run worse, which was expected. I need to check with an a/b testing though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc5a1c",
   "metadata": {},
   "source": [
    "#### Model number 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "635a74ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 5,342,619 \n",
      "The amount of time it took to vectorize was: 21.06203400000001\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3643  494]\n",
      " [ 527 3586]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.878921568627451\n",
      "Accuracy Score: 0.8762424242424243\n",
      "Recall Score: 0.8718696814976903\n",
      "f1 Score 0.8753814231661174\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,5))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train_sample, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train_sample)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ecd56",
   "metadata": {},
   "source": [
    "#### Model number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e2ef4d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 16.878854000000004\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "stop_words = 'the and of to is in br it that this as with for was film movie his on are have be one'.split(' ')\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3))\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e4097",
   "metadata": {},
   "source": [
    "This was a mechanical way to extract words but I have an idea of how to authomate the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe20d32",
   "metadata": {},
   "source": [
    "### 3) Tweeking Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2071e",
   "metadata": {},
   "source": [
    "#### Max df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bc6d6",
   "metadata": {},
   "source": [
    "Max_df and min_df are use to eliminate words based on some threshold. The idea is that some tokens instead of helping\n",
    "the model are only noise.\n",
    "<br>There are two basic approaches to handle this types of words. We can eliminate very common words(using **max_df**) or we can eliminate very rare words using min_df.\n",
    "<br><br> The idea with max_df is that if a word appears at least in a certain percentage of the sample then it should be removed.\n",
    "<br><br> The idea with min_df is that if a word appears in less document that in the theshold it should be ignored. \n",
    "<br><br> Notice that max_df will have a lot of overlapping with stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4783ca4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 0.4\n",
      "(16750, 3713413)\n",
      "This is the shape for 0.5\n",
      "(16750, 3713428)\n",
      "This is the shape for 0.6\n",
      "(16750, 3713440)\n",
      "This is the shape for 0.7\n",
      "(16750, 3713446)\n",
      "This is the shape for 0.8\n",
      "(16750, 3713448)\n",
      "This is the shape for 0.9\n",
      "(16750, 3713452)\n",
      "This is the shape for 1.0\n",
      "(16750, 3713457)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,11,1):\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=i/10)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i/10}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9808131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 0.4\n",
      "(16750, 63655)\n",
      "This is the shape for 0.5\n",
      "(16750, 63670)\n",
      "This is the shape for 0.6\n",
      "(16750, 63680)\n",
      "This is the shape for 0.7\n",
      "(16750, 63685)\n",
      "This is the shape for 0.8\n",
      "(16750, 63687)\n",
      "This is the shape for 0.9\n",
      "(16750, 63691)\n",
      "This is the shape for 1.0\n",
      "(16750, 63696)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,11,1):\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,1), max_df=i/10)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i/10}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38a720",
   "metadata": {},
   "source": [
    "I don't see much of a difference in this max_df, even at really low percentages. But, never know if this can really affect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "851aa8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>character</td>\n",
       "      <td>4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>films</td>\n",
       "      <td>4627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>life</td>\n",
       "      <td>4399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where</td>\n",
       "      <td>4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plot</td>\n",
       "      <td>4349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>little</td>\n",
       "      <td>4309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>show</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>love</td>\n",
       "      <td>4287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>over</td>\n",
       "      <td>4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>best</td>\n",
       "      <td>4199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>did</td>\n",
       "      <td>4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>know</td>\n",
       "      <td>4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>does</td>\n",
       "      <td>4065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>off</td>\n",
       "      <td>4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ever</td>\n",
       "      <td>3982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>man</td>\n",
       "      <td>3980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>better</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>here</td>\n",
       "      <td>3884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>end</td>\n",
       "      <td>3807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>your</td>\n",
       "      <td>3794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  counts\n",
       "0   character    4746\n",
       "1       films    4627\n",
       "2        life    4399\n",
       "3       where    4350\n",
       "4        plot    4349\n",
       "5      little    4309\n",
       "6        show    4296\n",
       "7        love    4287\n",
       "8        over    4270\n",
       "9        best    4199\n",
       "10        did    4190\n",
       "11       know    4167\n",
       "12       does    4065\n",
       "13        off    4059\n",
       "14       ever    3982\n",
       "15        man    3980\n",
       "16     better    3936\n",
       "17       here    3884\n",
       "18        end    3807\n",
       "19       your    3794"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Most common words in general\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,1), max_df=.2)\n",
    "list_of_words = cv.fit_transform(X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c2100",
   "metadata": {},
   "source": [
    "#### Model number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca7d72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 18.143799\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=.2 )\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "803f4ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 17.942894000000024\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=.3)\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b73dd",
   "metadata": {},
   "source": [
    "This models perform quiet similar to the models that where run with the decided stop_words (which was expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3cd0d",
   "metadata": {},
   "source": [
    "#### Model number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddfe39c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 18.375955000000033\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "stop_words = 'the and of to is in br it that this as with for was film movie his on are have be one'.split(' ')\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), max_df=.3)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34387d",
   "metadata": {},
   "source": [
    "There was a lot of overlap, and this little amount of words really make a difference in the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f83cc",
   "metadata": {},
   "source": [
    "#### Models using min_df alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75874e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 38025)\n",
      "This is the shape for 5\n",
      "(16750, 22483)\n",
      "This is the shape for 10\n",
      "(16750, 14804)\n",
      "This is the shape for 15\n",
      "(16750, 11432)\n",
      "This is the shape for 20\n",
      "(16750, 9375)\n",
      "This is the shape for 25\n",
      "(16750, 7969)\n",
      "This is the shape for 30\n",
      "(16750, 7034)\n",
      "This is the shape for 50\n",
      "(16750, 4803)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,10,15,20,25,30,50]:\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,1), min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c819647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 622962)\n",
      "This is the shape for 5\n",
      "(16750, 175106)\n",
      "This is the shape for 10\n",
      "(16750, 80501)\n",
      "This is the shape for 15\n",
      "(16750, 52307)\n",
      "This is the shape for 20\n",
      "(16750, 38496)\n",
      "This is the shape for 25\n",
      "(16750, 30253)\n",
      "This is the shape for 30\n",
      "(16750, 24837)\n",
      "This is the shape for 50\n",
      "(16750, 14359)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,10,15,20,25,30,50]:\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8c3cff7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 408279)\n",
      "This is the shape for 5\n",
      "(16750, 99325)\n",
      "This is the shape for 10\n",
      "(16750, 43980)\n",
      "This is the shape for 15\n",
      "(16750, 28243)\n",
      "This is the shape for 20\n",
      "(16750, 20688)\n",
      "This is the shape for 25\n",
      "(16750, 16255)\n",
      "This is the shape for 30\n",
      "(16750, 13391)\n",
      "This is the shape for 50\n",
      "(16750, 7828)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,10,15,20,25,30,50]:\n",
    "    count_vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e0b08",
   "metadata": {},
   "source": [
    "#### Model number 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28c5b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 99,325 \n",
      "The amount of time it took to vectorize was: 11.592953999999963\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3639  498]\n",
      " [ 505 3608]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      4137\n",
      "           1       0.88      0.88      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8787140769605456\n",
      "Accuracy Score: 0.8784242424242424\n",
      "Recall Score: 0.8772185752492099\n",
      "f1 Score 0.8779656892566006\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), min_df=5)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5048d13",
   "metadata": {},
   "source": [
    "#### Model number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19a7983f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 43,980 \n",
      "The amount of time it took to vectorize was: 10.890859999999975\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3592  545]\n",
      " [ 510 3603]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      4137\n",
      "           1       0.87      0.88      0.87      4113\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8686113789778206\n",
      "Accuracy Score: 0.8721212121212121\n",
      "Recall Score: 0.8760029175784099\n",
      "f1 Score 0.8722914901343661\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), min_df=10)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e748d255",
   "metadata": {},
   "source": [
    "Lets try some mixture of both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca693001",
   "metadata": {},
   "source": [
    "#### Model number 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e6c60c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 80,433 \n",
      "The amount of time it took to vectorize was: 13.848969000000011\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3630  507]\n",
      " [ 445 3668]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4137\n",
      "           1       0.88      0.89      0.89      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.878562874251497\n",
      "Accuracy Score: 0.8846060606060606\n",
      "Recall Score: 0.8918064672988086\n",
      "f1 Score 0.8851351351351352\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=10, max_df=0.3)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2f446",
   "metadata": {},
   "source": [
    "#### Model number 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b09b3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 80,457 \n",
      "The amount of time it took to vectorize was: 13.599285000000009\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3628  509]\n",
      " [ 449 3664]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4137\n",
      "           1       0.88      0.89      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8780254013898874\n",
      "Accuracy Score: 0.8838787878787879\n",
      "Recall Score: 0.8908339411621687\n",
      "f1 Score 0.8843832971276853\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=10, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb10688",
   "metadata": {},
   "source": [
    "The combination of both doesn't look better (need more testing to check if it is the same) but it may be faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c1dde",
   "metadata": {},
   "source": [
    "#### Model number 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5db7ebc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 175,062 \n",
      "The amount of time it took to vectorize was: 13.904557000000068\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3661  476]\n",
      " [ 474 3639]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      4137\n",
      "           1       0.88      0.88      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.884325637910085\n",
      "Accuracy Score: 0.8848484848484849\n",
      "Recall Score: 0.8847556528081693\n",
      "f1 Score 0.8845405930967428\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=5, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1301727",
   "metadata": {},
   "source": [
    "#### Model number 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7af35965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 622,918 \n",
      "The amount of time it took to vectorize was: 15.014494000000013\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3704  433]\n",
      " [ 467 3646]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4137\n",
      "           1       0.89      0.89      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8938465310125031\n",
      "Accuracy Score: 0.8909090909090909\n",
      "Recall Score: 0.886457573547289\n",
      "f1 Score 0.89013671875\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=2, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530642cd",
   "metadata": {},
   "source": [
    "I would like to understand exactly why when you start to increase the min_df you get a worse score if also you are working with a max_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acdfc36",
   "metadata": {},
   "source": [
    "#### Model number 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b463637",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train, new_y_train = remove_outliers(X_train, y_train , flesch_readability_ease)\n",
    "new_X_test, new_y_test = remove_outliers(X_test, y_test , flesch_readability_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ceacc618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,683,278 \n",
      "The amount of time it took to vectorize was: 19.877337999999995\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3698  410]\n",
      " [ 461 3611]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4108\n",
      "           1       0.90      0.89      0.89      4072\n",
      "\n",
      "    accuracy                           0.89      8180\n",
      "   macro avg       0.89      0.89      0.89      8180\n",
      "weighted avg       0.89      0.89      0.89      8180\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8980353145983586\n",
      "Accuracy Score: 0.893520782396088\n",
      "Recall Score: 0.8867878192534381\n",
      "f1 Score 0.8923761275176078\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=0.3)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, new_X_train, new_X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, new_y_train)\n",
    "    check_model(clf, X_test_vectorized, new_y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2858e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The really impresive stuff is that if you run the code only with the outliers then you get a perfect score. \n",
    "## At least in this split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04430225",
   "metadata": {},
   "source": [
    "#### Model number 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d664c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 584,934 \n",
      "The amount of time it took to vectorize was: 12.373823999999999\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3704  433]\n",
      " [ 470 3643]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4137\n",
      "           1       0.89      0.89      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8937684003925417\n",
      "Accuracy Score: 0.8905454545454545\n",
      "Recall Score: 0.8857281789448092\n",
      "f1 Score 0.8897301257784832\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(2,3), min_df=2, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6e8c699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 302,349 \n",
      "The amount of time it took to vectorize was: 7.228403\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3603  534]\n",
      " [ 548 3565]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      4137\n",
      "           1       0.87      0.87      0.87      4113\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8697243230056111\n",
      "Accuracy Score: 0.8688484848484849\n",
      "Recall Score: 0.8667639192803307\n",
      "f1 Score 0.8682415976619582\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(3,3), min_df=2, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "58c878e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,649,758 \n",
      "The amount of time it took to vectorize was: 17.841582000000002\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3749  388]\n",
      " [ 497 3616]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.88      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.903096903096903\n",
      "Accuracy Score: 0.8927272727272727\n",
      "Recall Score: 0.8791636275224897\n",
      "f1 Score 0.8909695700381913\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(2,3), max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959686cc",
   "metadata": {},
   "source": [
    "### 3.5) Tailored based stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8cc68b",
   "metadata": {},
   "source": [
    "### 4) Contrasting Models and A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b606db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is another Christian propaganda fil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman who hates cats (Alice Krige) and her s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beast Wars is a show that is over-hyped, overp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An excellent example of \"cowboy noir\", as it's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok, basically this is a popcorn sci-fi movie, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Jimmy Cagney races by your eyes constantly in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Very much a film from the times -- extremely l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>The Little Mermaid is one of my absolute favor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>With a simplistic story and an engaging heroin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The 63 year reign of Queen Victoria is perhaps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                contents  labels\n",
       "0      This movie is another Christian propaganda fil...       0\n",
       "1      A woman who hates cats (Alice Krige) and her s...       1\n",
       "2      Beast Wars is a show that is over-hyped, overp...       0\n",
       "3      An excellent example of \"cowboy noir\", as it's...       1\n",
       "4      Ok, basically this is a popcorn sci-fi movie, ...       1\n",
       "...                                                  ...     ...\n",
       "24995  Jimmy Cagney races by your eyes constantly in ...       1\n",
       "24996  Very much a film from the times -- extremely l...       0\n",
       "24997  The Little Mermaid is one of my absolute favor...       0\n",
       "24998  With a simplistic story and an engaging heroin...       1\n",
       "24999  The 63 year reign of Queen Victoria is perhaps...       1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83f69a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "for i1,i2 in kf.split(data):\n",
    "    lst1 = list(i1)\n",
    "    lst2 = list(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa6687d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=2, max_df=0.4)\n",
    "X = 1\n",
    "y = 1\n",
    "test_split = 1\n",
    "\n",
    "def model_run(cv, clf, model_name, X, y, test_split):\n",
    "    for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "        # Vectorization\n",
    "        start = time.process_time()\n",
    "        X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "        print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "        print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "\n",
    "        # Running the model\n",
    "        print(clf_name)\n",
    "        clf.fit(X_train_vectorized, y_train)\n",
    "        check_model(clf, X_test_vectorized, y_test)\n",
    "        print(\"_________________________________________________\")\n",
    "        \n",
    "def get_test_split():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "014b6dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12500</th>\n",
       "      <td>argh! this film hurts my head. and not in a go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12501</th>\n",
       "      <td>Istanbul is another one of those expatriate fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12502</th>\n",
       "      <td>As a history nut who is particularly intereste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12503</th>\n",
       "      <td>This is a very enjoyable film with excellent a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504</th>\n",
       "      <td>Me being of Irish origins, loved this movie, N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Jimmy Cagney races by your eyes constantly in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Very much a film from the times -- extremely l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>The Little Mermaid is one of my absolute favor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>With a simplistic story and an engaging heroin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The 63 year reign of Queen Victoria is perhaps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                contents  labels\n",
       "12500  argh! this film hurts my head. and not in a go...       0\n",
       "12501  Istanbul is another one of those expatriate fi...       0\n",
       "12502  As a history nut who is particularly intereste...       0\n",
       "12503  This is a very enjoyable film with excellent a...       1\n",
       "12504  Me being of Irish origins, loved this movie, N...       1\n",
       "...                                                  ...     ...\n",
       "24995  Jimmy Cagney races by your eyes constantly in ...       1\n",
       "24996  Very much a film from the times -- extremely l...       0\n",
       "24997  The Little Mermaid is one of my absolute favor...       0\n",
       "24998  With a simplistic story and an engaging heroin...       1\n",
       "24999  The 63 year reign of Queen Victoria is perhaps...       1\n",
       "\n",
       "[12500 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[~data.index.isin(i1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
