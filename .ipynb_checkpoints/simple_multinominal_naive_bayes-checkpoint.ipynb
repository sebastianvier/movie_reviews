{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e7cd9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python in build modules:\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "## EDA libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "## Metrics (sklearn)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "## Models (sklearn)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(y_true, prediction):\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_true, prediction))\n",
    "    print(\"\\n\")\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_true, prediction))\n",
    "    print(\"\\n\")\n",
    "    print(\"Other Metrics\")\n",
    "    print(f'Pression Score: {precision_score(y_true, prediction)}')\n",
    "    print(f'Accuracy Score: {accuracy_score(y_true, prediction)}')\n",
    "    print(f'Recall Score: {recall_score(y_true, prediction)}')\n",
    "    print(f'f1 Score {f1_score(y_true, prediction)}')\n",
    "    \n",
    "def check_model(clf, X_test, y_test):\n",
    "    prediction = clf.predict(X_test)\n",
    "    print_report(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ef8b2",
   "metadata": {},
   "source": [
    "### 1) Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd00805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "path = 'data/train/'\n",
    "\n",
    "count = 0\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "for label in ['neg','pos']:\n",
    "    filenames = os.listdir(path + label)\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        with open(os.path.join(path, label, filename), 'r') as f:\n",
    "            labels.append(1 if label == 'pos' else 0) # 1 is positve 0 is negative\n",
    "            contents.append(f.read())\n",
    "print(count)\n",
    "            \n",
    "data = pd.DataFrame({\n",
    "    'contents' : contents,\n",
    "    'labels': labels,\n",
    "\n",
    "})\n",
    "\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdecdb1c",
   "metadata": {},
   "source": [
    "#### Just to be clear negative is 0 and positive is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1935c7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab00242",
   "metadata": {},
   "source": [
    "Ok, the data is **completely balanced**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298663a9",
   "metadata": {},
   "source": [
    " ###### At this moment we are going to see 5 examples of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b3dd8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "\n",
      "\n",
      "The plot was quite interesting, with the Russian revolution background. I also enjoyed seeing Budapest as the movie was partly filmed there. Sadly, there was zero chemistry between the 2 main characters so it was hard to believe the love story between them. The love scenes were forced and mechanical. Jordan kirckland was really stiff, almost icy. Rob Stewart was quite charming and boyish, so she looked like his older sister rather than his girlfriend. The ending, when we finally figure out who was actually after them, was quite weak and made no sense whatsoever. I think I would have enjoyed this movie a lot better if the relationship between the 2 actors was slightly more credible.\n",
      "\n",
      "\n",
      "Well our standards have gone into the toilet. The direction was poor, the acting was mediocre and the writing was amateurish. And those are the good points. Hopefully there won't be a sequel. Otherwise, I might have to leave the country.\n",
      "\n",
      "\n",
      "This film is a travesty, and isn't fit to keep company with the superior original. The plot is an absolute mess, and the film is way too long. Everytime they're struggling, they desperately inject a sentimental reminder from the first film.<br /><br />\"Gregory's Girl\" is one of the top 10 British films of all time, this one is awful.\n",
      "\n",
      "\n",
      "Well I guess I know the answer to that question. For the MONEY! We have been so bombarded with Cat In The Hat advertising and merchandise that we almost believe there has to be something good about this movie. I admit, I thought the trailers looked bad, but I still had to give it a chance. Well I should have went with my instincts. It was a complete piece Hollywood trash. Once again proving that the average person can be programed into believing anything they say is good, must be good. Aside from the insulting fact that the film is only about 80 minutes long, it obviously started with a moth eaten script. It's chock full of failed attempts at senseless humor, and awful pastel sceneries. It jumps all over the universe with no destination nor direction. This is then compounded with, ............................yes I'll say it, BAD ACTING! I couldn't help but feel like I was watching \"Coffee Talk\" on SNL every time Mike Myers opened his mouth. Was the Cat intended to be a middle aged Jewish woman? Spencer Breslin and Dakota Fanning were no prize either, but Mr. Myers should disappear under a rock somewhere until he's ready to make another Austin Powers movie. F-, no stars, 0 on a scale of 1-10. Save your money!\n",
      "\n",
      "\n",
      "Oh where to begin. The cinematography was great. When the movie first started because of the initial landscape scenes I thought that I was in for a good movie. Then the cgi Bigfoot showed up .It looked like a cartoon drawing of the Lion king and king Kong's love child.It totally took away from the believability of the character.Now I knew there wasn't a Bigfoot chasing people hiking around the woods for no apparent reason but a cheesy cgi cartoon.So from then on the whole movie was shot for me.The money they flushed down the toilet for the cgi they could of spent on a costume like roger Patterson did. His was the best Bigfoot costume ever no one else could match his.I am a hardcore cheesy Bigfoot movie fan and I was warned about this movie but my compulsion led me to watching this movie and I was disappointed like the previous reviews warned me about. I know after you read this review you will still say \"I must watch Sasquatch hunters,must watch Sasquatch hunters.\" Then you will say why did I waste my good hard earned money on such a excruciatingly bad boring movie!\n",
      "\n",
      "\n",
      "positive\n",
      "\n",
      "\n",
      "Fragglerock is excellent in the way that Schindler's List was excellent. A Great watch for children and adults of all genders. Big noses can be seen as hinting towards phallic symbols, in the same way that H.R. Puff N Stuff had hinted towards marijuana smoking. Your kids will love this movie. I enjoyed it very much as a child. My father showed me this movie as a child. He enjoyed it as well and pointed out that the exaggerated noses were phallic symbols. Although at the time I had no clue about what those were. The movie is comedy and adventure. The storyline is wacky and cheerful. I and you shall enjoy this together.\n",
      "\n",
      "\n",
      "I can't believe how many people hate Hal Sparks! He was my favorite host of the show, hands down. I hate celebrity gossip and generally dislike talk shows, but when Hal Sparks hosted Talk Soup, it was must see TV for me. I rarely missed an episode during his run, and was saddened when the guest hosts started pouring in (although most of the guests still did a fine job). <br /><br />Anyway, for all the people who dislike Hal Sparks, I imagine they must have never seen the weekend specials. They were hour long episodes of Talk Soup that comprised the best clips from the entire week, and were padded out by sketch comedy bits. The original bits that Hal Sparks did were hilarious. In one he got possessed by a bad comedy demon, and in an exorcist like scene his head spun as he told dated jokes about airline food. One episode was dedicated to making fun of Multiplicity, as a bunch of cloned Hal Sparks kept multiplying through out the episode, over-running the studio.<br /><br />OK, maybe these don't sound as funny when I describe them, but all I know is that besides Talk Soup, the only other two shows I watched consistently during those years was The Simpsons and Late Night with Conan O'Brian. So if you like the comedy stylings of those shows, then you'd probably like Talk Soup during the Sparks years.<br /><br />That said, Henson and Tyler were both great hosts as well. All three hosts brought something different to the table but they were all fine comedians in my opinion. Of course, throughout the Tyler and guest star years, my interest in this show began to wane, but every now and then I catch The Soup, the show's spiritual successor, and sure enough, the new host can bring some pretty unexpected laughs from time to time.<br /><br />OK, I've wasted enough time talking about a TV show that isn't on the air anymore and on a channel that I generally despise. Go watch something else!\n",
      "\n",
      "\n",
      "This is a film that can make you want to see it again. I especially, liked the way it ended. I did not see the end coming, but when Laws was not blown away the first time, one suspects he will be back again.<br /><br />The story is gripping and could have been more psychological, but I understand the story needed to capture the viewer and the action was necessary for that.<br /><br />Hard to believe Michael Jr. could be so apparently unmoved as his younger brother and mother as blown away. But, I can appreciate the scene play couldn't really take our attention there because it had a greater story to tell.<br /><br />Some have complained about Hanks as a gangster. I believe that isn't justified. If his character had been any harder, he would not have cared if his son pulled a trigger or not.<br /><br />Eight Stars for this one. Although it was released in 2002, I just saw it for the first time yesterday on DVD.\n",
      "\n",
      "\n",
      "This film made for French TV deals with the tragic effect it has for a close knit family. When Leo, the young man at the center of the story is diagnosed as having the AIDS virus, announces it to his parents, they just can't believe it. The film is a character study on how this family deals with its subject.<br /><br />The director, Christophe Honore, has to be congratulated for bringing this frank account to the screen. Nowhere but in France could this story make it to the movies because of the subject matter.<br /><br />The news has a devastating effect on Marcel, the young brother who hears about what Leo has contracted, in spite of the way the parents want to shelter him from reality.<br /><br />Yaniss Lespart and Pierre Mignard do a convincing job in portraying the brothers.\n",
      "\n",
      "\n",
      "When you compare what Brian De Palma was doing in the 80's to what passes for entertainment today, his films keep looking better and better. \"Dressed To Kill, \"Blow Out\", \"Body Double\", \"Scarface\" and \"Carlito's Way\" are all superb works of a cinematic craftsman at the peak of his powers. The guy had a long run of better than average films. This is pure Hitchcock with an 80's dash of lurid perversion, an affectionately told tale of lust and murder with plenty of twists, huge helpings of style, a stunning Pino Donaggio score, and a trashy, giallo-inspired plot. De Palma's love of complex camera-work and luscious, blood-smudged visuals helps overcome the logical holes while the terrific performances of Dennis Franz, Keith Gordon (a good director in his own right), Nancy Allen (De Palma's wife at the time) and Michael Caine make every scene special. Let the virtuoso take you on a surreal, scary, erotically charged odyssey and you'll enjoy every frame of \"Dressed To Kill\".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in data.labels.unique():\n",
    "    print(\"negative\" if label ==  0 else \"positive\")\n",
    "    print(\"\\n\")\n",
    "    for content in data.contents[data.labels == label].sample(5):\n",
    "        print(content)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2f5d0",
   "metadata": {},
   "source": [
    "###### From now on I am going to be using the training data to explore the data so I can get some conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e48b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.contents\n",
    "y = data.labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "edfbbc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8387\n",
       "0    8363\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.labels.value_counts() # Just checking the proportions haven't change much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034f50c",
   "metadata": {},
   "source": [
    "###### Mean of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bfb077e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of all reviews: 1328.28\n",
      "Mean length in positive reviews: 1352.3945391677596\n",
      "Mean length in negative reviews: 1304.1033122085375\n",
      "Ratio positive: 1.0181547107294844\n",
      "Ration negative: 0.9817985004731966\n"
     ]
    }
   ],
   "source": [
    "mean_length_full = np.round(X_train.map(len).mean(),2)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "mean_lenght_pos = train_df[train_df.labels == 1].contents.map(len).mean()\n",
    "mean_length_neg = train_df[train_df.labels == 0].contents.map(len).mean()\n",
    "ratio_pos =  mean_lenght_pos / mean_length_full\n",
    "ratio_neg =  mean_length_neg / mean_length_full\n",
    "\n",
    "print(f'Mean length of all reviews: {mean_length_full}')\n",
    "print(f'Mean length in positive reviews: {mean_lenght_pos}')\n",
    "print(f'Mean length in negative reviews: {mean_length_neg}')\n",
    "print(f'Ratio positive: {ratio_pos}')\n",
    "print(f'Ration negative: {ratio_neg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd11a0",
   "metadata": {},
   "source": [
    "We can run an **A/B test** here, but there is an indication that the **length** of the commentary has **nothing to do** with the idea if it is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58751a6",
   "metadata": {},
   "source": [
    "###### Most common word for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9d57b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>226374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>110239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>97692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>91327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>72318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>br</td>\n",
       "      <td>68495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it</td>\n",
       "      <td>65011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>62845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>this</td>\n",
       "      <td>50974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>that</td>\n",
       "      <td>49116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>was</td>\n",
       "      <td>32075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>as</td>\n",
       "      <td>31526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>29811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>movie</td>\n",
       "      <td>29732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>with</td>\n",
       "      <td>29532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>28659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>film</td>\n",
       "      <td>26875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>you</td>\n",
       "      <td>23086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>22838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>not</td>\n",
       "      <td>20462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  number\n",
       "0     the  226374\n",
       "1     and  110239\n",
       "2      of   97692\n",
       "3      to   91327\n",
       "4      is   72318\n",
       "5      br   68495\n",
       "6      it   65011\n",
       "7      in   62845\n",
       "8    this   50974\n",
       "9    that   49116\n",
       "10    was   32075\n",
       "11     as   31526\n",
       "12    for   29811\n",
       "13  movie   29732\n",
       "14   with   29532\n",
       "15    but   28659\n",
       "16   film   26875\n",
       "17    you   23086\n",
       "18     on   22838\n",
       "19    not   20462"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words={'english'})\n",
    "list_of_words = cv.fit_transform(X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d71c93",
   "metadata": {},
   "source": [
    "### 2) Running the first models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a880f",
   "metadata": {},
   "source": [
    "#### Model number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27134e4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba790f",
   "metadata": {},
   "source": [
    "For some reason if I add the amount of ngram_range to for example 1,3 then I have a problem; I am going to test different stuff afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07155c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3612  525]\n",
      " [ 674 3439]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      4137\n",
      "           1       0.87      0.84      0.85      4113\n",
      "\n",
      "    accuracy                           0.85      8250\n",
      "   macro avg       0.86      0.85      0.85      8250\n",
      "weighted avg       0.86      0.85      0.85      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.8675580221997982\n",
      "Accuracy Score: 0.8546666666666667\n",
      "Recall Score: 0.836129345976173\n",
      "f1 Score 0.8515537947257644\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6e38d",
   "metadata": {},
   "source": [
    "#### Model number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4e570d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5f2e886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3663  474]\n",
      " [ 545 3568]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.8827313211281543\n",
      "Accuracy Score: 0.8764848484848485\n",
      "Recall Score: 0.8674933138828106\n",
      "f1 Score 0.8750459840588596\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe20d32",
   "metadata": {},
   "source": [
    "### Checking different count vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca7d72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4092eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_result = X_train_vectorized.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02f8c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=False)\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c9ace88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3682  455]\n",
      " [ 573 3540]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4137\n",
      "           1       0.89      0.86      0.87      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.886107634543179\n",
      "Accuracy Score: 0.8753939393939394\n",
      "Recall Score: 0.8606856309263311\n",
      "f1 Score 0.8732116428219042\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4783ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 0.4\n",
      "(16750, 3220267)\n",
      "This is the shape for 0.5\n",
      "(16750, 3220271)\n",
      "This is the shape for 0.6\n",
      "(16750, 3220274)\n",
      "This is the shape for 0.7\n",
      "(16750, 3220275)\n",
      "This is the shape for 0.8\n",
      "(16750, 3220276)\n",
      "This is the shape for 0.9\n",
      "(16750, 3220276)\n",
      "This is the shape for 1.0\n",
      "(16750, 3220276)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,11,1):\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=False, max_df=i/10)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i/10}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba5abe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 279654)\n",
      "This is the shape for 5\n",
      "(16750, 67094)\n",
      "This is the shape for 12\n",
      "(16750, 25427)\n",
      "This is the shape for 20\n",
      "(16750, 15013)\n",
      "This is the shape for 30\n",
      "(16750, 9999)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,12,20,30]:\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=False, min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "884db0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=False, min_df=2)\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb983933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3658  479]\n",
      " [ 543 3570]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4137\n",
      "           1       0.88      0.87      0.87      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.8816991849839466\n",
      "Accuracy Score: 0.8761212121212121\n",
      "Recall Score: 0.8679795769511306\n",
      "f1 Score 0.874785591766724\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b6fefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=False, min_df=10)\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b3ea589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3582  555]\n",
      " [ 576 3537]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      4137\n",
      "           1       0.86      0.86      0.86      4113\n",
      "\n",
      "    accuracy                           0.86      8250\n",
      "   macro avg       0.86      0.86      0.86      8250\n",
      "weighted avg       0.86      0.86      0.86      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.8643695014662757\n",
      "Accuracy Score: 0.862909090909091\n",
      "Recall Score: 0.8599562363238512\n",
      "f1 Score 0.8621572212065813\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e8aff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=False, max_df=0.4)\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5015bdb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3661  476]\n",
      " [ 528 3585]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.8827874907658212\n",
      "Accuracy Score: 0.8783030303030303\n",
      "Recall Score: 0.8716265499635303\n",
      "f1 Score 0.8771715194519206\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2f0e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=False, max_df=0.4, min_df=2)\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c450d777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3648  489]\n",
      " [ 524 3589]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.8800882785679255\n",
      "Accuracy Score: 0.8772121212121212\n",
      "Recall Score: 0.8725990761001702\n",
      "f1 Score 0.8763276767183494\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e6a7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=True, max_df=0.3)\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8bb00c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3642  495]\n",
      " [ 506 3607]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      4137\n",
      "           1       0.88      0.88      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.879327157484154\n",
      "Accuracy Score: 0.8786666666666667\n",
      "Recall Score: 0.8769754437150499\n",
      "f1 Score 0.8781497261107729\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7566014",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=True, max_features=12000)\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01a3f97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3514  623]\n",
      " [ 595 3518]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85      4137\n",
      "           1       0.85      0.86      0.85      4113\n",
      "\n",
      "    accuracy                           0.85      8250\n",
      "   macro avg       0.85      0.85      0.85      8250\n",
      "weighted avg       0.85      0.85      0.85      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.8495532480077276\n",
      "Accuracy Score: 0.8523636363636363\n",
      "Recall Score: 0.8553367371748116\n",
      "f1 Score 0.8524351829416041\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5702b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), lowercase=True, max_features=3)\n",
    "X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized  = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad28836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[1964 2173]\n",
      " [1622 2491]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.47      0.51      4137\n",
      "           1       0.53      0.61      0.57      4113\n",
      "\n",
      "    accuracy                           0.54      8250\n",
      "   macro avg       0.54      0.54      0.54      8250\n",
      "weighted avg       0.54      0.54      0.54      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics\n",
      "Pression Score: 0.5340909090909091\n",
      "Accuracy Score: 0.54\n",
      "Recall Score: 0.6056406515925116\n",
      "f1 Score 0.5676199156887319\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "\n",
    "for clf, clf_name in [(mnb, 'Multinomial Naive Bayes')]:\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
