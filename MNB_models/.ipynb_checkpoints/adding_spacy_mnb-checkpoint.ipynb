{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521deb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python Libraries\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "\n",
    "## EDA libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "## Spacy modules and libraries\n",
    "import spacy \n",
    "\n",
    "## Sklearn modules\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "## nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "## scipy\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "## My own functions\n",
    "sys.path.append(\"/Users/sebastianvier/Documents/code/movie_reviews\")\n",
    "from functions import print_report, check_model, vectorize_X\n",
    "sys.path.append(\"/Users/sebastianvier/Documents/code/movie_reviews/SVM_models\")\n",
    "\n",
    "\n",
    "def lematizer(x):\n",
    "    return \" \".join([token.lemma_ for token in model(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f6b2d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "## Importing the data\n",
    "\n",
    "path = 'data/train/'\n",
    "\n",
    "count = 0\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "for label in ['neg','pos']:\n",
    "    filenames = os.listdir(path + label)\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        with open(os.path.join(path, label, filename), 'r') as f:\n",
    "            labels.append(1 if label == 'pos' else 0) # 1 is positve 0 is negative\n",
    "            contents.append(f.read())\n",
    "print(count)\n",
    "            \n",
    "data = pd.DataFrame({\n",
    "    'contents' : contents,\n",
    "    'labels': labels,\n",
    "\n",
    "})\n",
    "\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True) # This code will shuffle the data (just in case!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd8aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.contents\n",
    "y = data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c050bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spacy lematizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c79208",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load(\"en_core_web_sm\", exclude=['ner', 'parser', 'tok2vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07c94241",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lematized_1 = X[:100].map(lematizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c9dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875088a",
   "metadata": {},
   "source": [
    "### Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8229e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 63,386 \n",
      "The amount of time it took to vectorize was: 2.823738999999989\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3612  525]\n",
      " [ 674 3439]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      4137\n",
      "           1       0.87      0.84      0.85      4113\n",
      "\n",
      "    accuracy                           0.85      8250\n",
      "   macro avg       0.86      0.85      0.85      8250\n",
      "weighted avg       0.86      0.85      0.85      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8675580221997982\n",
      "Accuracy Score: 0.8546666666666667\n",
      "Recall Score: 0.836129345976173\n",
      "f1 Score 0.8515537947257644\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9627417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 63,260 \n",
      "The amount of time it took to vectorize was: 2.7196720000000028\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3620  517]\n",
      " [ 668 3445]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      4137\n",
      "           1       0.87      0.84      0.85      4113\n",
      "\n",
      "    accuracy                           0.86      8250\n",
      "   macro avg       0.86      0.86      0.86      8250\n",
      "weighted avg       0.86      0.86      0.86      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8695103483089349\n",
      "Accuracy Score: 0.8563636363636363\n",
      "Recall Score: 0.837588135181133\n",
      "f1 Score 0.8532507739938081\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lematized, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f03c4b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 2,991,762 \n",
      "The amount of time it took to vectorize was: 13.421976\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3663  474]\n",
      " [ 545 3568]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8827313211281543\n",
      "Accuracy Score: 0.8764848484848485\n",
      "Recall Score: 0.8674933138828106\n",
      "f1 Score 0.8750459840588596\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57c349b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 63,260 \n",
      "The amount of time it took to vectorize was: 2.8266649999999913\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3620  517]\n",
      " [ 668 3445]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      4137\n",
      "           1       0.87      0.84      0.85      4113\n",
      "\n",
      "    accuracy                           0.86      8250\n",
      "   macro avg       0.86      0.86      0.86      8250\n",
      "weighted avg       0.86      0.86      0.86      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8695103483089349\n",
      "Accuracy Score: 0.8563636363636363\n",
      "Recall Score: 0.837588135181133\n",
      "f1 Score 0.8532507739938081\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lematized, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e23526",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load(\"en_core_web_md\", exclude=['ner', 'parser', 'tok2vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4c87468",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lematized_2 = X[:100].map(lematizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cddbfb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_lematized_1 == X_lematized_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4806ba0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 63,260 \n",
      "The amount of time it took to vectorize was: 2.745069000000001\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3620  517]\n",
      " [ 668 3445]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      4137\n",
      "           1       0.87      0.84      0.85      4113\n",
      "\n",
      "    accuracy                           0.86      8250\n",
      "   macro avg       0.86      0.86      0.86      8250\n",
      "weighted avg       0.86      0.86      0.86      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8695103483089349\n",
      "Accuracy Score: 0.8563636363636363\n",
      "Recall Score: 0.837588135181133\n",
      "f1 Score 0.8532507739938081\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lematized, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3543894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   2.9s\n",
      "[CV] END .................................................... total time=   2.9s\n",
      "[CV] END .................................................... total time=   2.9s\n",
      "[CV] END .................................................... total time=   2.9s\n",
      "84.35\n",
      "0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.8s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1,1))),\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "cv = 5\n",
    "scorer = make_scorer(f1_score)\n",
    "result = cross_val_score(pipeline, X_lematized, y, cv=cv, scoring=scorer, verbose=2)\n",
    "\n",
    "print(round(result.mean() * 100 , 2))\n",
    "print(round(result.std()  * 100 , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa90c434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   9.3s\n",
      "[CV] END .................................................... total time=   9.3s\n",
      "[CV] END .................................................... total time=   9.2s\n",
      "[CV] END .................................................... total time=   9.4s\n",
      "87.63\n",
      "0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   46.8s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1,2))),\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "cv = 5\n",
    "scorer = make_scorer(f1_score)\n",
    "result = cross_val_score(pipeline, X_lematized, y, cv=cv, scoring=scorer, verbose=2)\n",
    "\n",
    "print(round(result.mean() * 100 , 2))\n",
    "print(round(result.std()  * 100 , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c858a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  23.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  24.0s\n",
      "[CV] END .................................................... total time=  23.7s\n",
      "[CV] END .................................................... total time=  24.4s\n",
      "[CV] END .................................................... total time=  23.8s\n",
      "88.65\n",
      "0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1,3))),\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "cv = 5\n",
    "scorer = make_scorer(f1_score)\n",
    "result = cross_val_score(pipeline, X_lematized, y, cv=cv, scoring=scorer, verbose=2)\n",
    "\n",
    "print(round(result.mean() * 100 , 2))\n",
    "print(round(result.std()  * 100 , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "433c2387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  15.7s\n",
      "[CV] END .................................................... total time=  15.5s\n",
      "[CV] END .................................................... total time=  15.9s\n",
      "[CV] END .................................................... total time=  15.3s\n",
      "88.72\n",
      "0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1,3), min_df=2, max_df=.5)),\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "cv = 5\n",
    "scorer = make_scorer(f1_score)\n",
    "result = cross_val_score(pipeline, X_lematized, y, cv=cv, scoring=scorer, verbose=2)\n",
    "\n",
    "print(round(result.mean() * 100 , 2))\n",
    "print(round(result.std()  * 100 , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "579c8b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  14.6s\n",
      "[CV] END .................................................... total time=  14.8s\n",
      "[CV] END .................................................... total time=  14.7s\n",
      "[CV] END .................................................... total time=  15.6s\n",
      "88.41\n",
      "0.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1,3), min_df=3, max_df=.5)),\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "cv = 5\n",
    "scorer = make_scorer(f1_score)\n",
    "result = cross_val_score(pipeline, X_lematized, y, cv=cv, scoring=scorer, verbose=2)\n",
    "\n",
    "print(round(result.mean() * 100 , 2))\n",
    "print(round(result.std()  * 100 , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8542b876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sebastianvier/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11822a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c607c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_lemmatizer(x):\n",
    "    return lematizer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9402b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lematized = X.map(w_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0ef87404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 63,260 \n",
      "The amount of time it took to vectorize was: 2.7692349999999806\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3620  517]\n",
      " [ 668 3445]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      4137\n",
      "           1       0.87      0.84      0.85      4113\n",
      "\n",
      "    accuracy                           0.86      8250\n",
      "   macro avg       0.86      0.86      0.86      8250\n",
      "weighted avg       0.86      0.86      0.86      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8695103483089349\n",
      "Accuracy Score: 0.8563636363636363\n",
      "Recall Score: 0.837588135181133\n",
      "f1 Score 0.8532507739938081\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lematized, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e64aa428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   2.9s\n",
      "[CV] END .................................................... total time=   2.9s\n",
      "[CV] END .................................................... total time=   2.9s\n",
      "[CV] END .................................................... total time=   2.9s\n",
      "84.35\n",
      "0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.7s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1,1))),\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "cv = 5\n",
    "scorer = make_scorer(f1_score)\n",
    "result = cross_val_score(pipeline, X_lematized, y, cv=cv, scoring=scorer, verbose=2)\n",
    "\n",
    "print(round(result.mean() * 100 , 2))\n",
    "print(round(result.std()  * 100 , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f35c23c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 16 \n",
      "The amount of time it took to vectorize was: 3.5451789999997345\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[2791 1346]\n",
      " [1991 2122]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.67      0.63      4137\n",
      "           1       0.61      0.52      0.56      4113\n",
      "\n",
      "    accuracy                           0.60      8250\n",
      "   macro avg       0.60      0.60      0.59      8250\n",
      "weighted avg       0.60      0.60      0.59      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.6118800461361015\n",
      "Accuracy Score: 0.5955151515151516\n",
      "Recall Score: 0.5159251154874788\n",
      "f1 Score 0.5598206041419338\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pos, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c1722d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b3abd0478cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_pos' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pos, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = TfidfVectorizer(ngram_range=(4,7))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "159c77f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pos(x):\n",
    "    return \" \".join([token.pos_ for token in model(x)])\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62172c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [14:07<00:00, 29.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "my_values = tqdm(X)\n",
    "X_pos = list(zip(map(get_pos, my_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaddb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos.to_csv(\"X_pos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78acdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_1 = list(map(lambda x: x[0],X_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de0e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_1 complete\n"
     ]
    }
   ],
   "source": [
    "X_train_pos, X_test_pos, y_train, y_test = train_test_split(X_pos_1, y, test_size=0.33, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,3), min_df=2, max_df=.5)\n",
    "cv_pos= CountVectorizer(ngram_range=(5,11))\n",
    "\n",
    "for vec, vec_pos , clf, clf_name in [(cv ,cv_pos, mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('vec_1 complete')\n",
    "    X_train_vectorized_pos, X_test_vectorized_pos = vectorize_X(vec_pos, X_train_pos, X_test_pos)\n",
    "    X_train_vectorized = hstack((X_train_vectorized, X_train_vectorized_pos))\n",
    "    X_test_vectorized  = hstack((X_test_vectorized, X_test_vectorized_pos))\n",
    "    \n",
    "    print('vectorization complete')\n",
    "\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
