{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6133c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python in build-in modules:\n",
    "import os, re, csv, sys\n",
    "\n",
    "## EDA libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "## Metrics (sklearn)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "## Models (sklearn)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "## My own functions\n",
    "sys.path.append(\"/Users/sebastianvier/Documents/code/movie_reviews\")\n",
    "from functions import print_report, check_model, vectorize_X\n",
    "sys.path.append(\"/Users/sebastianvier/Documents/code/movie_reviews/SVM_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d42ab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "## Importing the data\n",
    "\n",
    "path = 'data/train/'\n",
    "\n",
    "count = 0\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "for label in ['neg','pos']:\n",
    "    filenames = os.listdir(path + label)\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        with open(os.path.join(path, label, filename), 'r') as f:\n",
    "            labels.append(1 if label == 'pos' else 0) # 1 is positve 0 is negative\n",
    "            contents.append(f.read())\n",
    "print(count)\n",
    "            \n",
    "data = pd.DataFrame({\n",
    "    'contents' : contents,\n",
    "    'labels': labels,\n",
    "\n",
    "})\n",
    "\n",
    "movie_data = data.sample(frac=1, random_state=42).reset_index(drop=True) # This code will shuffle the data (just in case!)\n",
    "X_movie = data.contents\n",
    "y_movie = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4f64eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_review.txt \u001b[34mtest\u001b[m\u001b[m              \u001b[34mtrain\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4068071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/amazon_review.txt\", \"r\") as f:\n",
    "    amazon_lines =  list(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67bbbdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360000\n"
     ]
    }
   ],
   "source": [
    "number = int(np.ceil(len(amazon_lines)/10))\n",
    "print(number)\n",
    "lines = amazon_lines[:number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1ab76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliter(x):\n",
    "    return x.split(\":\", 1)\n",
    "\n",
    "title = []\n",
    "comment = []\n",
    "label = []\n",
    "for line in lines:\n",
    "    full_info = line[11:].split(\":\",1)\n",
    "    title.append(full_info[0])\n",
    "    comment.append(full_info[1])\n",
    "    if line[:10] == '__label__1':\n",
    "        label.append(0)\n",
    "    elif line[:10] == '__label__2':\n",
    "        label.append(1)\n",
    "        \n",
    "amazon_rev = pd.DataFrame({\n",
    "    \"title\"   : title,\n",
    "    \"contents\" : comment,\n",
    "    \"labels\"   : label,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076c01b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    182351\n",
       "0    177649\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_rev.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52145f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = movie_data.contents\n",
    "y_train = movie_data.labels\n",
    "X_test = amazon_rev.contents\n",
    "y_test = amazon_rev.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e4851",
   "metadata": {},
   "source": [
    "### 1) Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37af80a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,3), max_df=.5, min_df=2)\n",
    "\n",
    "X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b263b99a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnb.fit(X_train_vectorized, y_train)\n",
    "check_model(mnb, X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d93632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4650 1302]\n",
      " [2018 7571]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      5952\n",
      "           1       0.85      0.79      0.82      9589\n",
      "\n",
      "    accuracy                           0.79     15541\n",
      "   macro avg       0.78      0.79      0.78     15541\n",
      "weighted avg       0.79      0.79      0.79     15541\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8532627070889215\n",
      "Accuracy Score: 0.7863715333633614\n",
      "Recall Score: 0.7895505266451142\n",
      "f1 Score 0.820171162387607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_1(x):\n",
    "    return \"book\" in x\n",
    "\n",
    "amazon_book_rev = amazon_rev[amazon_rev.title.map(filter_1)]\n",
    "\n",
    "X_train = movie_data.contents\n",
    "y_train = movie_data.labels\n",
    "X_test = amazon_book_rev.contents\n",
    "y_test = amazon_book_rev.labels\n",
    "\n",
    "X_test_vectorized = cv.transform(X_test)\n",
    "mnb.fit(X_train_vectorized, y_train)\n",
    "check_model(mnb, X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84a41316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[2831  540]\n",
      " [ 776 2976]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      3371\n",
      "           1       0.85      0.79      0.82      3752\n",
      "\n",
      "    accuracy                           0.82      7123\n",
      "   macro avg       0.82      0.82      0.82      7123\n",
      "weighted avg       0.82      0.82      0.82      7123\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8464163822525598\n",
      "Accuracy Score: 0.8152463849501614\n",
      "Recall Score: 0.7931769722814499\n",
      "f1 Score 0.8189323059988992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_1(x):\n",
    "    return ((\"movie\" in x) or (\"movies\" in x))\n",
    "\n",
    "amazon_book_rev = amazon_rev[amazon_rev.title.map(filter_1)]\n",
    "\n",
    "X_train = movie_data.contents\n",
    "y_train = movie_data.labels\n",
    "X_test = amazon_book_rev.contents\n",
    "y_test = amazon_book_rev.labels\n",
    "\n",
    "X_test_vectorized = cv.transform(X_test)\n",
    "mnb.fit(X_train_vectorized, y_train)\n",
    "check_model(mnb, X_test_vectorized, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
