{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7cd9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python in build modules:\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "## EDA libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "## Metrics (sklearn)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "## Models (sklearn)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "## My own functions\n",
    "from functions import print_report, check_model, vectorize_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ef8b2",
   "metadata": {},
   "source": [
    "### 1) Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd00805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "## Importing the data\n",
    "\n",
    "path = 'data/train/'\n",
    "\n",
    "count = 0\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "for label in ['neg','pos']:\n",
    "    filenames = os.listdir(path + label)\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        with open(os.path.join(path, label, filename), 'r') as f:\n",
    "            labels.append(1 if label == 'pos' else 0) # 1 is positve 0 is negative\n",
    "            contents.append(f.read())\n",
    "print(count)\n",
    "            \n",
    "data = pd.DataFrame({\n",
    "    'contents' : contents,\n",
    "    'labels': labels,\n",
    "\n",
    "})\n",
    "\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True) # This code will shuffle the data (just in case!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f315e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I desperately want to give this movie a 10...I really do. Some movies, especially horror movies are so budget that they are good. A wise-cracking ninja scarecrow who can implement corn cobs as lethal weaponry...definitely fits this 'budget to brilliance' system. The depth of the movie is definitely its strong point and the twists and turns it implements, keeping the audience at the edge of their seats really drives the creepy...ninja... puberty-stricken... pre-thirty year old student...non-cowboy drawing...wise-cracking...son-of-a-bitch scarecrow into the limelight as the creepiest horror icon of the year. All I can really say is, 'can you dig it' and recommend watching movies such as Frankenfish if you enjoy this sort of hilarious horror.<br /><br />(WHAT THE HELL WERE THEY SMOKING!?'\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sample = data.sample()\n",
    "print(sample.contents.iloc[0])\n",
    "print(sample.labels.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdecdb1c",
   "metadata": {},
   "source": [
    "#### Just to be clear negative is 0 and positive is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1935c7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab00242",
   "metadata": {},
   "source": [
    "Ok, the data is **completely balanced**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298663a9",
   "metadata": {},
   "source": [
    " ###### At this moment we are going to see 5 examples of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b3dd8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "\n",
      "\n",
      "Realistic movie,sure,except for the fact that the characters don't look like to be scared. When Billy Zane tries to kill someone, he feels bad...but he doesn't look like to. That's why I don't like his performance in this movie. Tom Berenger is again playing a soldier. No good thrill, realistic sequences. Not always shooting, that is one great thing. Well filmed. I hate the helicopter sequence, cause only one terrorist kills almost the whole marine bunch...I give it **and a half out of *****\n",
      "\n",
      "\n",
      "this movie was banned in england? why? tom savini, george romero, dario argento, lucio fulci and others had done far worse before and have continued to so since...<br /><br />this movie has all the basic elements of a decent 70s or early 80's horror film. good looking girls (who can't act to save their lives, by the way), a terrible lightning storm with a torrential downpour, a scythe, a crazy brother wandering around the family estate, and actually a pretty damn good twist at the end. but banned? seriously. when the English parliament banned this movie, the italians probably laughed their collective asses off at how backwards and prudish the brits really were.<br /><br />there was maybe two minutes of total screen time devoted to the violence and gore (which was greatly underdone). there was nudity but no sex although allusions to sex were made, obviously. but absolutely nothing worthy of being banned.<br /><br />i would like to see what could have been done if the filmmakers had a decent budget to work with. as it stands, the film is entertaining, but the lack of picture and sound quality take away from the end result.<br /><br />banned... what a joke...\n",
      "\n",
      "\n",
      "positive\n",
      "\n",
      "\n",
      "Even longtime Shirley fans may be surprised by \"Now and Forever.\" The movie was filmed with Paramount studios  not with Shirley's parent company Twentieth Century Fox  in 1934, before Fox producer Darryl Zanuck had perfected the successful Shirley formula (cute songs, cold hearts for her to melt, young couples for her to play cupid to, happy endings). Thus \"Now and Forever\" falls into the category of a Shirley vehicle without the standard Shirley story. It is an awkward position for any movie, but this impressive, talented cast makes it work.<br /><br />Gary Cooper and Carole Lombard star as fun-loving, irresponsible con artists Jerry and Toni Day. The only thing that this devoted yet dysfunctional duo seems to hate more than being together is being apart. When they are suddenly landed with custody of Jerry's young daughter Penny (Shirley Temple), it is Toni  and not Penny, as many believe  who persuades Jerry to give up his criminal career. But Jerry flounders at his desk job, and desperate to prove that he can provide for his new family, he soon returns to thieving and dishonesty. In a standard Shirley device, Penny tries to melt the heart of crusty curmudgeon Felix Evans, the victim of one of Jerry's cons, but her attempt fails, for Evans is revealed to be a con artist himself, and he blackmails Jerry into helping him steal jewels. The drama, gunfight, death, and sorrow that follow all make this film a very unusual one for Little Miss Sunshine. There is no happy ending, no dancing, and only one song sequence (the cute number \"The World Owes Me a Living\").<br /><br />But this does not mean that Shirley fans should avoid \"Now and Forever.\" Rather, it's divergence from the usual Shirley story make it more interesting and memorable than many of her other films. But beware: You should avoid colorized version of this film, and see it in black-and-white if you can. The color is bright, garish, and unrealistic, and in many scenes, Shirley's famous curls are actually red instead of blonde. Yikes!\n",
      "\n",
      "\n",
      "Matthew McConaughey is a mysterious man waiting for Agent Wesley Doyle (Powers Boothe) in his FBI office. He claims to have information about a serial killer chased by FBI. When Agent Doyle arrives in the office, he tells him that the serial killer is indeed his dead brother. Agent Doyle requests some evidence, and the man tells the story of his life, since his childhood. They were a simple family of three: his widow father Meiks (Bill Paxton), his brother and himself. One night, his father gathers the two brothers and tells them that an angel of God had just visited him and assigned his family to destroy demons. What happens next is one of the most scary movie I have ever seen. <br /><br />I watched this movie four months ago on VHS, and yesterday I watched again, now on DVD. Although being a low-budget movie, the screenplay is sharp, with no flaw. The cast is outstanding, but I would like to highlight the performance of Matt O'Leary as the young Felton. It is a very difficult and complex role to be performed by a young teenager. The direction of Bill Paxton is remarkable. There is no explicit violence in this horror movie. A great debut behind the camera. I regret the Brazilian title of this movie: 'A Mão do Diabo' (The Devil's Hand'). If at least it were 'The God's Hand', it might be acceptable. But calling this movie as 'the devil's hand' is indeed ridiculous. Brent Hanley, the screenwriter, did not deserve such a lack of respect from the Brazilian distributor. This film is highly recommended. My vote is eight.<br /><br />Title (Brazil): \"A Mão do Diabo\" (\"The Devil's Hand\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in data.labels.unique():\n",
    "    print(\"negative\" if label ==  0 else \"positive\")\n",
    "    print(\"\\n\")\n",
    "    for content in data.contents[data.labels == label].sample(2):\n",
    "        print(content)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2f5d0",
   "metadata": {},
   "source": [
    "###### From now on I am going to be using the training data to explore the data so I can get some conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e48b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.contents\n",
    "y = data.labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54397f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5b4cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4137\n",
       "1    4113\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edfbbc31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8387\n",
       "0    8363\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.labels.value_counts() # Just checking the proportions haven't change much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9304e8",
   "metadata": {},
   "source": [
    "### Does it has to do something with length?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034f50c",
   "metadata": {},
   "source": [
    "###### Mean of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfb077e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of all reviews: 1328.28\n",
      "Mean length in positive reviews: 1352.3945391677596\n",
      "Mean length in negative reviews: 1304.1033122085375\n",
      "Ratio positive: 1.0181547107294844\n",
      "Ration negative: 0.9817985004731966\n"
     ]
    }
   ],
   "source": [
    "mean_length_full = np.round(X_train.map(len).mean(),2)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "mean_lenght_pos = train_df[train_df.labels == 1].contents.map(len).mean()\n",
    "mean_length_neg = train_df[train_df.labels == 0].contents.map(len).mean()\n",
    "ratio_pos =  mean_lenght_pos / mean_length_full\n",
    "ratio_neg =  mean_length_neg / mean_length_full\n",
    "\n",
    "print(f'Mean length of all reviews: {mean_length_full}')\n",
    "print(f'Mean length in positive reviews: {mean_lenght_pos}')\n",
    "print(f'Mean length in negative reviews: {mean_length_neg}')\n",
    "print(f'Ratio positive: {ratio_pos}')\n",
    "print(f'Ration negative: {ratio_neg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0e4ea0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16750.000000\n",
       "mean      1328.283522\n",
       "std       1009.709272\n",
       "min         53.000000\n",
       "25%        702.250000\n",
       "50%        981.000000\n",
       "75%       1612.000000\n",
       "max      13704.000000\n",
       "Name: contents, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.map(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd11a0",
   "metadata": {},
   "source": [
    "We can run an **A/B test** here, but there is an indication that the **length** of the commentary has **nothing to do** with the idea if it is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587a175",
   "metadata": {},
   "source": [
    "###### Describing of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c84568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the length of model when positive:\n",
      "count     8387.000000\n",
      "mean      1352.394539\n",
      "std       1053.673512\n",
      "min         70.000000\n",
      "25%        695.000000\n",
      "50%        982.000000\n",
      "75%       1659.500000\n",
      "max      13704.000000\n",
      "Name: contents, dtype: float64\n",
      "\n",
      "\n",
      "Describe the length of model when negative:\n",
      "count    8363.000000\n",
      "mean     1304.103312\n",
      "std       963.063593\n",
      "min        53.000000\n",
      "25%       710.000000\n",
      "50%       981.000000\n",
      "75%      1554.000000\n",
      "max      8754.000000\n",
      "Name: contents, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Describe the length of model when positive:')\n",
    "print(train_df[train_df.labels == 1].contents.map(len).describe())\n",
    "print('\\n')\n",
    "print('Describe the length of model when negative:')\n",
    "print(train_df[train_df.labels == 0].contents.map(len).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e50f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage: 80\n",
      "positive\n",
      "1917.0\n",
      "negative\n",
      "1799.0\n",
      "percentage: 84\n",
      "positive\n",
      "2168.7199999999993\n",
      "negative\n",
      "2015.0\n",
      "percentage: 88\n",
      "positive\n",
      "2514.0\n",
      "negative\n",
      "2328.120000000001\n",
      "percentage: 92\n",
      "positive\n",
      "3005.0\n",
      "negative\n",
      "2755.12\n",
      "percentage: 96\n",
      "positive\n",
      "3815.119999999999\n",
      "negative\n",
      "3521.079999999998\n",
      "percentage: 100\n",
      "positive\n",
      "13704.0\n",
      "negative\n",
      "8754.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,101,4):\n",
    "    print(f'percentage: {i}')\n",
    "    print('positive')\n",
    "    print(np.percentile(train_df[train_df.labels == 1].contents.map(len), i))\n",
    "    print('negative')\n",
    "    print(np.percentile(train_df[train_df.labels == 0].contents.map(len), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aebcaf06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage: 990\n",
      "positive\n",
      "5305.979999999996\n",
      "negative\n",
      "5143.779999999975\n",
      "percentage: 992\n",
      "positive\n",
      "5484.296000000002\n",
      "negative\n",
      "5336.039999999994\n",
      "percentage: 994\n",
      "positive\n",
      "5669.788000000008\n",
      "negative\n",
      "5551.656000000003\n",
      "percentage: 996\n",
      "positive\n",
      "5807.0\n",
      "negative\n",
      "5664.655999999999\n",
      "percentage: 998\n",
      "positive\n",
      "5976.435999999969\n",
      "negative\n",
      "5879.103999999999\n",
      "percentage: 1000\n",
      "positive\n",
      "13704.0\n",
      "negative\n",
      "8754.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(990,1001,2):\n",
    "    print(f'percentage: {i}')\n",
    "    print('positive')\n",
    "    print(np.percentile(train_df[train_df.labels == 1].contents.map(len), i/10))\n",
    "    print('negative')\n",
    "    print(np.percentile(train_df[train_df.labels == 0].contents.map(len), i/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c47b0447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>13704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24379</th>\n",
       "      <td>10363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9762</th>\n",
       "      <td>9420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>9345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>7134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>7068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17881</th>\n",
       "      <td>6461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12808</th>\n",
       "      <td>6309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       contents\n",
       "1564      13704\n",
       "24379     10363\n",
       "9762       9420\n",
       "2192       9345\n",
       "4628       8180\n",
       "6010       7134\n",
       "10265      7068\n",
       "2920       6620\n",
       "17881      6461\n",
       "12808      6309"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_df[train_df.labels == 1].contents.map(len)).sort_values('contents', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fcc8f38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8163</th>\n",
       "      <td>8754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10539</th>\n",
       "      <td>7761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14589</th>\n",
       "      <td>7731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19270</th>\n",
       "      <td>7382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17302</th>\n",
       "      <td>7164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7926</th>\n",
       "      <td>7144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>6295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>6230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15868</th>\n",
       "      <td>6041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>6037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       contents\n",
       "8163       8754\n",
       "10539      7761\n",
       "14589      7731\n",
       "19270      7382\n",
       "17302      7164\n",
       "7926       7144\n",
       "5592       6295\n",
       "5791       6230\n",
       "15868      6041\n",
       "1069       6037"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_df[train_df.labels == 0].contents.map(len)).sort_values('contents', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21e679",
   "metadata": {},
   "source": [
    "###### Doesn't seem likely. We can see there is a little divergence when the comments start to get longer that people with good reviews will tend to write longer comments. #trustinhumanityrestored (not really)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe81516",
   "metadata": {},
   "source": [
    "### What about number of paragraphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c06ac233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_paragraph(x):\n",
    "    return x.count('<br /><br />') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe17f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = pd.concat([train_df.contents.apply(count_paragraph), train_df.labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee8b1bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAE9CAYAAAD6c07jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYxElEQVR4nO3df7BfdX3n8efLoIhWRpALGxNssJNVgVlAsplYdh0LrcTVGtYpTuwqWaWNZVMUt7sd6M5Ot7OTWXa261bcQof1R4K/mBSlULeoTCp2WlnwgigEZIigkCWSoHWlOoNNfO8f30/K1+Qmnwvme27CfT5mvnPOeX/POZ/PzST3lfM5v1JVSJJ0IM+Z6w5Ikg59hoUkqcuwkCR1GRaSpC7DQpLUZVhIkrqOmOsOTMpxxx1XS5YsmetuSNJh5Y477ni8qqb2rj9rw2LJkiVMT0/PdTck6bCS5Nsz1R2GkiR1GRaSpC7DQpLUZVhIkromFhZJXpHkrrHPD5JckuTYJDcneaBNjxnb5rIkW5Pcn+TcsfqZSe5u312RJJPqtyRpXxMLi6q6v6pOr6rTgTOBHwHXA5cCm6tqKbC5LZPkZGA1cAqwErgyyYK2u6uAtcDS9lk5qX5LkvY11DDUOcA3q+rbwCpgY6tvBM5r86uAa6vqyap6CNgKLE+yEDi6qm6t0fPUrxnbRpI0gKHCYjXwqTZ/QlVtB2jT41t9EfDI2DbbWm1Rm9+7LkkayMTDIsnzgDcDf9pbdYZaHaA+U1trk0wnmd65c+fT66gkab+GOLJ4A3BnVT3Wlh9rQ0u06Y5W3wacOLbdYuDRVl88Q30fVXV1VS2rqmVTU/vcrS5JeoaGCIu38dQQFMCNwJo2vwa4Yay+OsmRSU5idCL79jZU9USSFe0qqAvGtpEkDWCiz4ZK8gLgV4B3j5UvBzYluRB4GDgfoKq2JNkE3AvsAtZV1e62zUXABuAo4Kb2GczOqz4+8TamLnr7xNuQpGdqomFRVT8CXrJX7buMro6aaf31wPoZ6tPAqZPooySpzzu4JUldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUNdGwSPLiJNcl+UaS+5K8JsmxSW5O8kCbHjO2/mVJtia5P8m5Y/Uzk9zdvrsiSSbZb0nST5v0kcUHgM9V1SuB04D7gEuBzVW1FNjclklyMrAaOAVYCVyZZEHbz1XAWmBp+6yccL8lSWMmFhZJjgZeC3wYoKp+XFXfB1YBG9tqG4Hz2vwq4NqqerKqHgK2AsuTLASOrqpbq6qAa8a2kSQNYJJHFi8HdgIfTfLVJB9K8kLghKraDtCmx7f1FwGPjG2/rdUWtfm965KkgUwyLI4AXg1cVVVnAD+kDTntx0znIeoA9X13kKxNMp1keufOnU+3v5Kk/ZhkWGwDtlXVbW35Okbh8VgbWqJNd4ytf+LY9ouBR1t98Qz1fVTV1VW1rKqWTU1NHbQfRJLmu4mFRVV9B3gkySta6RzgXuBGYE2rrQFuaPM3AquTHJnkJEYnsm9vQ1VPJFnRroK6YGwbSdIAjpjw/i8GPpHkecCDwDsZBdSmJBcCDwPnA1TVliSbGAXKLmBdVe1u+7kI2AAcBdzUPpKkgUw0LKrqLmDZDF+ds5/11wPrZ6hPA6ce1M5JkmbNO7glSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkromGRZJvJbk7yV1Jplvt2CQ3J3mgTY8ZW/+yJFuT3J/k3LH6mW0/W5NckSST7Lck6acNcWTxS1V1elUta8uXApuraimwuS2T5GRgNXAKsBK4MsmCts1VwFpgafusHKDfkqRmLoahVgEb2/xG4Lyx+rVV9WRVPQRsBZYnWQgcXVW3VlUB14xtI0kawKTDooAvJLkjydpWO6GqtgO06fGtvgh4ZGzbba22qM3vXZckDeSICe//rKp6NMnxwM1JvnGAdWc6D1EHqO+7g1EgrQV42cte9nT7Kknaj4keWVTVo226A7geWA481oaWaNMdbfVtwIljmy8GHm31xTPUZ2rv6qpaVlXLpqamDuaPIknz2sTCIskLk7xozzzweuAe4EZgTVttDXBDm78RWJ3kyCQnMTqRfXsbqnoiyYp2FdQFY9tIkgYwyWGoE4Dr21WuRwCfrKrPJfkKsCnJhcDDwPkAVbUlySbgXmAXsK6qdrd9XQRsAI4CbmofSdJAJhYWVfUgcNoM9e8C5+xnm/XA+hnq08CpB7uPkqTZ8Q5uSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1TTwskixI8tUkn23Lxya5OckDbXrM2LqXJdma5P4k547Vz0xyd/vuiiSZdL8lSU8Z4sjivcB9Y8uXApuraimwuS2T5GRgNXAKsBK4MsmCts1VwFpgafusHKDfkqRmomGRZDHwRuBDY+VVwMY2vxE4b6x+bVU9WVUPAVuB5UkWAkdX1a1VVcA1Y9tIkgYw6SOLPwJ+F/jJWO2EqtoO0KbHt/oi4JGx9ba12qI2v3d9H0nWJplOMr1z586D8gNIkiYYFkneBOyoqjtmu8kMtTpAfd9i1dVVtayqlk1NTc2yWUlSz6zCIsnm2dT2chbw5iTfAq4Fzk7yceCxNrREm+5o628DThzbfjHwaKsvnqEuSRrIAcMiyfOTHAscl+SYdiXTsUmWAC890LZVdVlVLa6qJYxOXP9lVb0duBFY01ZbA9zQ5m8EVic5MslJjE5k396Gqp5IsqJdBXXB2DaSpAEc0fn+3cAljILhDp4aEvoB8MfPsM3LgU1JLgQeBs4HqKotSTYB9wK7gHVVtbttcxGwATgKuKl9JEkDOWBYVNUHgA8kubiqPvhMG6mqW4Bb2vx3gXP2s956YP0M9Wng1GfaviTpZ9M7sgCgqj6Y5BeBJePbVNU1E+qXJOkQMquwSPIx4BeAu4A9Q0N77nmQJD3LzSosgGXAye2mOEnSPDPb+yzuAf7RJDsiSTp0zfbI4jjg3iS3A0/uKVbVmyfSK0nSIWW2YfGfJtkJSdKhbbZXQ31p0h2RJB26Zns11BM89Tym5wHPBX5YVUdPqmOSpEPHbI8sXjS+nOQ8YPkkOiRJOvQ8o6fOVtWfAWcf3K5Ikg5Vsx2GesvY4nMY3XfhPReSNE/M9mqoXx2b3wV8i9Gb7SRJ88Bsz1m8c9IdkSQdumb78qPFSa5PsiPJY0k+3d6vLUmaB2Z7gvujjF5O9FJG77/+81aTJM0Dsw2Lqar6aFXtap8NgC+5lqR5YrZh8XiStydZ0D5vB747yY5Jkg4dsw2LdwFvBb4DbAd+DfCktyTNE7O9dPY/A2uq6m8BkhwL/CGjEJEkPcvN9sjin+wJCoCq+h5wxmS6JEk61Mw2LJ6T5Jg9C+3IYrZHJZKkw9xsf+H/d+DLSa5j9JiPtwLrJ9YrSdIhZbZ3cF+TZJrRwwMDvKWq7p1ozyRJh4xZDyW1cDAgJGkeekaPKJckzS+GhSSpy7CQJHUZFpKkromFRZLnJ7k9ydeSbEnyB61+bJKbkzzQpuP3b1yWZGuS+5OcO1Y/M8nd7bsrkmRS/ZYk7WuSRxZPAmdX1WnA6cDKJCuAS4HNVbUU2NyWSXIysBo4BVgJXJlkQdvXVcBaYGn7rJxgvyVJe5lYWNTI37XF57ZPMXod68ZW3wic1+ZXAddW1ZNV9RCwFVieZCFwdFXdWlUFXDO2jSRpABM9Z9EeZ34XsAO4uapuA06oqu0AbXp8W30R8MjY5ttabVGb37suSRrIRMOiqnZX1enAYkZHCaceYPWZzkPUAer77iBZm2Q6yfTOnTufdn8lSTMb5Gqoqvo+cAujcw2PtaEl2nRHW20bcOLYZouBR1t98Qz1mdq5uqqWVdWyqSlf5CdJB8skr4aaSvLiNn8U8MvANxi9y3tNW20NcEObvxFYneTIJCcxOpF9exuqeiLJinYV1AVj20iSBjDJx4wvBDa2K5qeA2yqqs8muRXYlORC4GHgfICq2pJkE6PnT+0C1lXV7ravi4ANwFHATe0jSRrIxMKiqr7ODC9IqqrvAufsZ5v1zPDo86qaBg50vkOSNEHewS1J6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktR1xFx3QIe+7VdeNvE2Fv6b/zLxNiQ9cx5ZSJK6DAtJUpdhIUnqMiwkSV2GhSSpa2JhkeTEJF9Mcl+SLUne2+rHJrk5yQNteszYNpcl2Zrk/iTnjtXPTHJ3++6KJJlUvyVJ+5rkkcUu4Heq6lXACmBdkpOBS4HNVbUU2NyWad+tBk4BVgJXJlnQ9nUVsBZY2j4rJ9hvSdJeJhYWVbW9qu5s808A9wGLgFXAxrbaRuC8Nr8KuLaqnqyqh4CtwPIkC4Gjq+rWqirgmrFtJEkDGOScRZIlwBnAbcAJVbUdRoECHN9WWwQ8MrbZtlZb1Ob3rkuSBjLxsEjyc8CngUuq6gcHWnWGWh2gPlNba5NMJ5neuXPn0++sJGlGEw2LJM9lFBSfqKrPtPJjbWiJNt3R6tuAE8c2Xww82uqLZ6jvo6qurqplVbVsamrq4P0gkjTPTezZUO2KpQ8D91XV+8e+uhFYA1zepjeM1T+Z5P3ASxmdyL69qnYneSLJCkbDWBcAH5xUv3Vo+eYHVw3Szi9cfEN/JWkem+SDBM8C3gHcneSuVvs9RiGxKcmFwMPA+QBVtSXJJuBeRldSrauq3W27i4ANwFHATe0jSRrIxMKiqv6amc83AJyzn23WA+tnqE8Dpx683kmSng7v4JYkdfk+i8PAjj/5nxNv4/jf+u2JtyHp8OWRhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeryfRbSAdzxJ786SDtn/tafD9KO9Ex5ZCFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKlrYmGR5CNJdiS5Z6x2bJKbkzzQpseMfXdZkq1J7k9y7lj9zCR3t++uSJJJ9VmSNLNJHllsAFbuVbsU2FxVS4HNbZkkJwOrgVPaNlcmWdC2uQpYCyxtn733KUmasImFRVX9FfC9vcqrgI1tfiNw3lj92qp6sqoeArYCy5MsBI6uqlurqoBrxraRJA1k6HMWJ1TVdoA2Pb7VFwGPjK23rdUWtfm96zNKsjbJdJLpnTt3HtSOS9J8dqic4J7pPEQdoD6jqrq6qpZV1bKpqamD1jlJmu+GDovH2tASbbqj1bcBJ46ttxh4tNUXz1CXJA1o6LC4EVjT5tcAN4zVVyc5MslJjE5k396Gqp5IsqJdBXXB2DaSpIFM7LWqST4FvA44Lsk24PeBy4FNSS4EHgbOB6iqLUk2AfcCu4B1VbW77eoiRldWHQXc1D6SpAFNLCyq6m37+eqc/ay/Hlg/Q30aOPUgdk06bNzyv944SDuv+83/PUg7OnwdKie4JUmHMMNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lS18QeJCjp8PfZj7xhkHbe9C4fJn2o88hCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqctLZyUdsq7dcO4g7az+158fpJ3DmUcWkqQuw0KS1GVYSJK6DAtJUpcnuCVpPz50zeRPsP/GBYfHyXWPLCRJXYaFJKnLYShJOkT9j09Ofhjsfb8+u2Gww+bIIsnKJPcn2Zrk0rnujyTNJ4dFWCRZAPwx8AbgZOBtSU6e215J0vxxWIQFsBzYWlUPVtWPgWuBVXPcJ0maNw6XsFgEPDK2vK3VJEkDSFXNdR+6kpwPnFtVv9GW3wEsr6qL91pvLbC2Lb4CuH/Qjv6044DH52Hbtm/7tn94t//zVTW1d/FwuRpqG3Di2PJi4NG9V6qqq4Grh+rUgSSZrqpl861t27d92392tn+4DEN9BVia5KQkzwNWAzfOcZ8kad44LI4sqmpXkt8GPg8sAD5SVVvmuFuSNG8cFmEBUFV/AfzFXPfjaZjL4bC5Hoqzfdu3/WdZ+4fFCW5J0tw6XM5ZSJLmkGFxkCX5SJIdSe6Zg7ZPTPLFJPcl2ZLkvQO3//wktyf5Wmv/D4Zsv/VhQZKvJvns0G239r+V5O4kdyWZnoP2X5zkuiTfaH8PXjNg269oP/eezw+SXDJg++9rf+/uSfKpJM8fqu3W/ntb21uG+Lln+l2T5NgkNyd5oE2POVjtGRYH3wZg5Ry1vQv4nap6FbACWDfwY1GeBM6uqtOA04GVSVYM2D7Ae4H7Bm5zb79UVafP0eWTHwA+V1WvBE5jwD+Lqrq//dynA2cCPwKuH6LtJIuA9wDLqupURhfCrB6i7db+qcBvMnraxGnAm5IsnXCzG9j3d82lwOaqWgpsbssHhWFxkFXVXwHfm6O2t1fVnW3+CUa/KAa7071G/q4tPrd9BjsplmQx8EbgQ0O1eShJcjTwWuDDAFX146r6/hx15xzgm1X17QHbPAI4KskRwAuY4V6sCXoV8H+q6kdVtQv4EvAvJ9ngfn7XrAI2tvmNwHkHqz3D4lkqyRLgDOC2gdtdkOQuYAdwc1UN2f4fAb8L/GTANvdWwBeS3NGeKDCklwM7gY+2obgPJXnhwH3YYzXwqaEaq6r/C/wh8DCwHfh/VfWFodoH7gFem+QlSV4A/At++kbioZxQVdth9J9H4PiDtWPD4lkoyc8BnwYuqaofDNl2Ve1uwxCLgeXt8HzikrwJ2FFVdwzR3gGcVVWvZvSE5HVJXjtg20cArwauqqozgB9yEIchZqvdOPtm4E8HbPMYRv+rPgl4KfDCJG8fqv2qug/4r8DNwOeArzEaFn7WMCyeZZI8l1FQfKKqPjNX/WjDH7cw3Pmbs4A3J/kWo6cSn53k4wO1/Q+q6tE23cFovH75gM1vA7aNHc1dxyg8hvYG4M6qemzANn8ZeKiqdlbV3wOfAX5xwPapqg9X1aur6rWMhoceGLL95rEkCwHadMfB2rFh8SySJIzGq++rqvfPQftTSV7c5o9i9A/4G0O0XVWXVdXiqlrCaAjkL6tqsP9ZAiR5YZIX7ZkHXs9oeGIQVfUd4JEkr2ilc4B7h2p/zNsYcAiqeRhYkeQF7d/BOQx8oUOS49v0ZcBbGP7PAEaPQVrT5tcANxysHR82d3AfLpJ8CngdcFySbcDvV9WHB2r+LOAdwN3tvAHA77W734ewENjYXlb1HGBTVc3JJaxz5ATg+tHvKo4APllVnxu4DxcDn2hDQQ8C7xyy8TZe/yvAu4dst6puS3IdcCej4Z+vMvyd1J9O8hLg74F1VfW3k2xspt81wOXApiQXMgrQ8w9ae97BLUnqcRhKktRlWEiSugwLSVKXYSFJ6jIsJEldhoU0YUmWJPn1n3Efl7TLUqU5YVhIk7cE+JnCAriE0cPxpDlhWEgdSS5I8vX2no6PJfn5JJtbbXO7Y5ckG5JckeTLSR5M8mttF5cD/7y94+F97WGL/y3JV9o+3t22f12SW8beR/GJjLyH0fOOvpjR+0oWtLbuyejdGe+bmz8ZzSfewS0dQJJTgP/A6AGBjyc5ltGjn6+pqo1J3gVcwVOPgl4I/DPglYwevXAdo4f5/buqelPb51pGT0X9p0mOBP4myZ4npJ4BnMLo8dp/09q9Ism/ZfSejMeTnAksau9tYM8jVqRJ8shCOrCzgeuq6nGAqvoe8Brgk+37jzEKhz3+rKp+UlX3Mnr8x0xeD1zQHslyG/ASYM+Lcm6vqm1V9RPgLkZDWHt7EHh5kg8mWQkM+mRhzU+GhXRgof8Cp/Hvn9xr2/3t8+I9b5WrqpPG3r0wvv1uZjj6b88cOo3RU33XMU9f9qRhGRbSgW0G3toeEEcbhvoyT72y818Bf93ZxxPAi8aWPw9c1B4nT5J/PIuXFP3DPpIcBzynqj4N/Efm5jHkmmc8ZyEdQFVtSbIe+FKS3YyeZvoe4CNJ/j2jN9P1nuz6dWBXkq8xem/yBxgNL93ZHqe9k/7rL68GbkqyndGVUR9Nsuc/e5c9zR9Letp86qwkqcthKElSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6/j+01AVkReMpPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(6,5))\n",
    "axs = sns.countplot(data=paragraphs, x='contents')\n",
    "axs.set_xlim(-1,9.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ddc1198e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(6,5))\n",
    "axs = sns.countplot(data=paragraphs[paragraphs.labels == 1], x='contents')\n",
    "axs.set_xlim(-1,9.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce6cd650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(6,5))\n",
    "axs = sns.countplot(data=paragraphs[paragraphs.labels == 0], x='contents')\n",
    "axs.set_xlim(-1,9.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db9804f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the n parragraphs of model when positive:\n",
      "count    8387.000000\n",
      "mean        2.972696\n",
      "std         2.518918\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         4.000000\n",
      "max        26.000000\n",
      "Name: contents, dtype: float64\n",
      "\n",
      "\n",
      "Describe the n parragraphs of model when negative:\n",
      "count    8363.000000\n",
      "mean        3.116705\n",
      "std         2.797950\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         4.000000\n",
      "max        47.000000\n",
      "Name: contents, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Describe the n parragraphs of model when positive:')\n",
    "print(paragraphs[paragraphs.labels == 1].contents.describe())\n",
    "print('\\n')\n",
    "print('Describe the n parragraphs of model when negative:')\n",
    "print(paragraphs[paragraphs.labels == 0].contents.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bb3e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage: 80\n",
      "positive\n",
      "5.0\n",
      "negative\n",
      "5.0\n",
      "percentage: 84\n",
      "positive\n",
      "5.0\n",
      "negative\n",
      "5.0\n",
      "percentage: 88\n",
      "positive\n",
      "6.0\n",
      "negative\n",
      "6.0\n",
      "percentage: 92\n",
      "positive\n",
      "7.0\n",
      "negative\n",
      "7.0\n",
      "percentage: 96\n",
      "positive\n",
      "8.0\n",
      "negative\n",
      "8.0\n",
      "percentage: 100\n",
      "positive\n",
      "26.0\n",
      "negative\n",
      "47.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,101,4):\n",
    "    print(f'percentage: {i}')\n",
    "    print('positive')\n",
    "    print(np.percentile(paragraphs[paragraphs.labels == 1].contents, i))\n",
    "    print('negative')\n",
    "    print(np.percentile(paragraphs[paragraphs.labels == 0].contents , i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34ba21",
   "metadata": {},
   "source": [
    "###### Doesn't seem likely.  There are cases that are outliers but nothing really there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8f4bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can actually look for the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93bd5f",
   "metadata": {},
   "source": [
    "### What about complexity and readiability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f47e3",
   "metadata": {},
   "source": [
    "###### Flesch ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72805488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flesch_readability_ease(text):\n",
    "    if len(text) > 0:\n",
    "        text = text.replace(\"?\", \".\")\n",
    "        total_words = len(text.split())\n",
    "        total_sentences = len(text.split('.'))\n",
    "        total_sillables = sum(list(map(lambda x: 1 if x in [\"a\",\"i\",\"e\",\"o\",\"u\",\"y\",\"A\",\"E\",\"I\",\"O\",\"U\",\"y\"] else 0, text)))\n",
    "        return 206.835 - (1.015 *  total_words/ total_sentences) - 84.6 * (total_sillables / total_words)\n",
    "    \n",
    "def remove_outliers(X, y , function):\n",
    "    boolean = X.apply(function) > 0\n",
    "    return X[boolean],y[boolean]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbed9ff",
   "metadata": {},
   "source": [
    "It is not that easy, because there are times where you have ? or ! instead of a . And then you may have multiple !? or ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c5210724",
   "metadata": {},
   "outputs": [],
   "source": [
    "flesch_ease = train_df.contents.map(flesch_readability_ease)\n",
    "flesch_ease = pd.concat([train_df, flesch_ease], axis=1)\n",
    "flesch_ease.columns = ['contents', 'labels', 'ease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bb1b1324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the ease of model when positive:\n",
      "count    8387.000000\n",
      "mean       39.431971\n",
      "std        14.529193\n",
      "min      -134.725000\n",
      "25%        31.274001\n",
      "50%        40.201469\n",
      "75%        48.880102\n",
      "max        87.286162\n",
      "Name: ease, dtype: float64\n",
      "\n",
      "\n",
      "Describe the ease of model when negative:\n",
      "count    8363.000000\n",
      "mean       42.887833\n",
      "std        14.907786\n",
      "min      -210.452353\n",
      "25%        35.030668\n",
      "50%        43.851477\n",
      "75%        52.018772\n",
      "max       103.367105\n",
      "Name: ease, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Describe the ease of model when positive:')\n",
    "print(flesch_ease[flesch_ease.labels == 1].ease.describe())\n",
    "print('\\n')\n",
    "print('Describe the ease of model when negative:')\n",
    "print(flesch_ease[flesch_ease.labels == 0].ease.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af616585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage: 80\n",
      "positive\n",
      "50.940267383746146\n",
      "negative\n",
      "54.076604486839805\n",
      "percentage: 84\n",
      "positive\n",
      "52.82375255102043\n",
      "negative\n",
      "55.837750000000035\n",
      "percentage: 88\n",
      "positive\n",
      "54.82556181930695\n",
      "negative\n",
      "57.75107385620919\n",
      "percentage: 92\n",
      "positive\n",
      "57.522019145859474\n",
      "negative\n",
      "60.312583618136266\n",
      "percentage: 96\n",
      "positive\n",
      "61.7592260392157\n",
      "negative\n",
      "64.2719031597529\n",
      "percentage: 100\n",
      "positive\n",
      "87.28616216216219\n",
      "negative\n",
      "103.36710526315791\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,101,4):\n",
    "    print(f'percentage: {i}')\n",
    "    print('positive')\n",
    "    print(np.percentile(flesch_ease[flesch_ease.labels == 1].ease, i))\n",
    "    print('negative')\n",
    "    print(np.percentile(flesch_ease[flesch_ease.labels == 0].ease, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11019b",
   "metadata": {},
   "source": [
    "###### The difference in complexity is not crazy, but is there (at least for this model) . Can we use this knowledge in some sort of way? The process is also a little bit memory consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cab672",
   "metadata": {},
   "source": [
    "##### There are outliers also outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "697e4e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Smallville episode Justice is the best episode of Smallville ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! It's my favorite episode of Smallville! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\""
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Outliers of low understandability\n",
    "flesch_ease[flesch_ease.ease < -0].contents.sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a58c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are reviews that make little sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ef8cc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flesch_ease[flesch_ease.ease < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f905b021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Fiendish Plot of Dr. Fu Manchu (1980). This is hands down the worst film I've ever seen. What a sad way for a great comedian to go out.\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Outliers of high understandability\n",
    "flesch_ease[flesch_ease.ease > 80].contents.sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb7428fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flesch_ease[flesch_ease.ease > 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2be9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>labels</th>\n",
       "      <th>ease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12131</th>\n",
       "      <td>Ernst Lubitsch's contribution to the American ...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.428436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12827</th>\n",
       "      <td>The name (Frau) of the main character is the G...</td>\n",
       "      <td>0</td>\n",
       "      <td>40.173923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>Upon The Straight Story release in 1999, it wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>34.813930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13762</th>\n",
       "      <td>This documentary explores a story covered in P...</td>\n",
       "      <td>1</td>\n",
       "      <td>23.340646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>Tho 35 years old, Groove Tube looks a lot like...</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.854812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>Yes, Kazaam is one of those horribly bad movie...</td>\n",
       "      <td>0</td>\n",
       "      <td>35.520517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>The 3rd and in my view the best of the Blackad...</td>\n",
       "      <td>1</td>\n",
       "      <td>39.070429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>!!!!! POSSIBLE SPOILER !!!!!&lt;br /&gt;&lt;br /&gt;You`d ...</td>\n",
       "      <td>0</td>\n",
       "      <td>29.169732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>I cant understand at all why so many Godzilla ...</td>\n",
       "      <td>0</td>\n",
       "      <td>25.185830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>This movie is just plain silly. Almost every s...</td>\n",
       "      <td>1</td>\n",
       "      <td>61.992981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16750 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                contents  labels       ease\n",
       "12131  Ernst Lubitsch's contribution to the American ...       1  40.428436\n",
       "12827  The name (Frau) of the main character is the G...       0  40.173923\n",
       "2912   Upon The Straight Story release in 1999, it wa...       1  34.813930\n",
       "13762  This documentary explores a story covered in P...       1  23.340646\n",
       "6369   Tho 35 years old, Groove Tube looks a lot like...       1  -3.854812\n",
       "...                                                  ...     ...        ...\n",
       "21575  Yes, Kazaam is one of those horribly bad movie...       0  35.520517\n",
       "5390   The 3rd and in my view the best of the Blackad...       1  39.070429\n",
       "860    !!!!! POSSIBLE SPOILER !!!!!<br /><br />You`d ...       0  29.169732\n",
       "15795  I cant understand at all why so many Godzilla ...       0  25.185830\n",
       "23654  This movie is just plain silly. Almost every s...       1  61.992981\n",
       "\n",
       "[16750 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flesch_ease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a5d12",
   "metadata": {},
   "source": [
    "###### So how is the data distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0e0cc037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=\"labels\", y=\"ease\",\n",
    "                    data=flesch_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ad539cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=\"labels\", y=\"ease\",\n",
    "                    data=flesch_ease[flesch_ease.ease > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71263b00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=\"labels\", y=\"ease\",\n",
    "                    data=flesch_ease[flesch_ease.ease > 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35979931",
   "metadata": {},
   "source": [
    "###### There is a difference but not that much, when you take outliers positive reviews are just a bit harder to read. At least in this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58751a6",
   "metadata": {},
   "source": [
    "###### Most common word for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d57b119",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>226374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>110239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>97692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>91327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>72318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>br</td>\n",
       "      <td>68495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it</td>\n",
       "      <td>65011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>62845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>this</td>\n",
       "      <td>50974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>that</td>\n",
       "      <td>49116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>was</td>\n",
       "      <td>32075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>as</td>\n",
       "      <td>31526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>29811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>movie</td>\n",
       "      <td>29732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>with</td>\n",
       "      <td>29532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>28659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>film</td>\n",
       "      <td>26875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>you</td>\n",
       "      <td>23086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>22838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>not</td>\n",
       "      <td>20462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     the  226374\n",
       "1     and  110239\n",
       "2      of   97692\n",
       "3      to   91327\n",
       "4      is   72318\n",
       "5      br   68495\n",
       "6      it   65011\n",
       "7      in   62845\n",
       "8    this   50974\n",
       "9    that   49116\n",
       "10    was   32075\n",
       "11     as   31526\n",
       "12    for   29811\n",
       "13  movie   29732\n",
       "14   with   29532\n",
       "15    but   28659\n",
       "16   film   26875\n",
       "17    you   23086\n",
       "18     on   22838\n",
       "19    not   20462"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Most common words in general\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'})\n",
    "list_of_words = cv.fit_transform(X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8e007398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>116902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>60296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>51458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>45150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>38653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>33731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>br</td>\n",
       "      <td>33091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>32486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>23998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>23519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as</td>\n",
       "      <td>17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>with</td>\n",
       "      <td>15599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>15132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>was</td>\n",
       "      <td>14698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>film</td>\n",
       "      <td>14146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>14098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movie</td>\n",
       "      <td>12845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>his</td>\n",
       "      <td>11603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>11422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you</td>\n",
       "      <td>11294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     the  116902\n",
       "1     and   60296\n",
       "2      of   51458\n",
       "3      to   45150\n",
       "4      is   38653\n",
       "5      in   33731\n",
       "6      br   33091\n",
       "7      it   32486\n",
       "8    that   23998\n",
       "9    this   23519\n",
       "10     as   17752\n",
       "11   with   15599\n",
       "12    for   15132\n",
       "13    was   14698\n",
       "14   film   14146\n",
       "15    but   14098\n",
       "16  movie   12845\n",
       "17    his   11603\n",
       "18     on   11422\n",
       "19    you   11294"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_X_train = train_df.contents[train_df.labels == 1]\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,1))\n",
    "list_of_words = cv.fit_transform(pos_X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0736ff54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>116902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>60296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>51458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>45150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>38653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>33731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>br</td>\n",
       "      <td>33091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>32486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>23998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>23519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as</td>\n",
       "      <td>17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>with</td>\n",
       "      <td>15599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>15132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>was</td>\n",
       "      <td>14698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>film</td>\n",
       "      <td>14146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but</td>\n",
       "      <td>14098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movie</td>\n",
       "      <td>12845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>his</td>\n",
       "      <td>11603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>11422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you</td>\n",
       "      <td>11294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  counts\n",
       "0     the  116902\n",
       "1     and   60296\n",
       "2      of   51458\n",
       "3      to   45150\n",
       "4      is   38653\n",
       "5      in   33731\n",
       "6      br   33091\n",
       "7      it   32486\n",
       "8    that   23998\n",
       "9    this   23519\n",
       "10     as   17752\n",
       "11   with   15599\n",
       "12    for   15132\n",
       "13    was   14698\n",
       "14   film   14146\n",
       "15    but   14098\n",
       "16  movie   12845\n",
       "17    his   11603\n",
       "18     on   11422\n",
       "19    you   11294"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_X_train = train_df.contents[train_df.labels == 0]\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'})\n",
    "list_of_words = cv.fit_transform(pos_X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75815e",
   "metadata": {},
   "source": [
    "#### 2) Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ab04a8b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-182-132cbefa9b97>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-182-132cbefa9b97>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    stopwords=[i.replace(\",\"\").strip() for i in stopwords]\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "with open(\"stop_words.txt\", \"r\") as stopwords:\n",
    "    stopwords=[i.replace(\",\"\").strip() for i in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ba22dd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"aint\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"arent\", \"arise\", \"around\", \"as\", \"as\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"cant\", \"cause\", \"causes\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"cmon\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"couldn\", \"couldnt\", \"couldnt\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"cs\", \"ct\", \"cu\", \"currently\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"didnt\", \"different\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doesnt\", \"doing\", \"don\", \"done\", \"dont\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"effect\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"empty\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"h2\", \"h3\", \"had\", \"hadn\", \"hadnt\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"hasnt\", \"have\", \"haven\", \"havent\", \"having\", \"he\", \"hed\", \"hed\", \"hell\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"heres\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"hes\", \"hh\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"hj\", \"ho\", \"home\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"hows\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"id\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"ill\", \"im\", \"im\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"invention\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"isnt\", \"it\", \"itd\", \"itd\", \"itll\", \"its\", \"its\", \"itself\", \"iv\", \"ive\", \"ix\", \"iy\", \"iz\", \"j\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"know\", \"known\", \"knows\", \"ko\", \"l\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"lets\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mightnt\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"mustnt\", \"my\", \"myself\", \"n\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needn\", \"neednt\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"other\", \"others\", \"otherwise\", \"ou\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"present\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"s2\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shant\", \"she\", \"shed\", \"shed\", \"shell\", \"shes\", \"shes\", \"should\", \"shouldn\", \"shouldnt\", \"shouldve\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"system\", \"sz\", \"t\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"thatll\", \"thats\", \"thats\", \"thatve\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"therell\", \"thereof\", \"therere\", \"theres\", \"theres\", \"thereto\", \"thereupon\", \"thereve\", \"these\", \"they\", \"theyd\", \"theyd\", \"theyll\", \"theyre\", \"theyre\", \"theyve\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"ts\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"ut\", \"v\", \"va\", \"value\", \"various\", \"vd\", \"ve\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"wa\", \"want\", \"wants\", \"was\", \"wasn\", \"wasnt\", \"wasnt\", \"way\", \"we\", \"wed\", \"wed\", \"welcome\", \"well\", \"well\", \"well-b\", \"went\", \"were\", \"were\", \"weren\", \"werent\", \"werent\", \"weve\", \"what\", \"whatever\", \"whatll\", \"whats\", \"whats\", \"when\", \"whence\", \"whenever\", \"whens\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"wheres\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"wholl\", \"whom\", \"whomever\", \"whos\", \"whos\", \"whose\", \"why\", \"whys\", \"wi\", \"widely\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"wont\", \"words\", \"world\", \"would\", \"wouldn\", \"wouldnt\", \"wouldnt\", \"www\", \"x\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"youd\", \"youll\", \"your\", \"youre\", \"youre\", \"yours\", \"yourself\", \"yourselves\", \"youve\", \"yr\", \"ys\", \"yt\", \"z\", \"zero\", \"zi\", \"zz\",']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a3e56711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['films', 'character', 'movies', 'characters', 'man', 'then', 'show', 'little', 'where', 'could', 'being', 'does', 'any', 'over', 'while', 'know', 'here', 'did', 'these', 'years']\n"
     ]
    }
   ],
   "source": [
    "pos_X_train = train_df.contents[train_df.labels == 1]\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'}, max_df=.2)\n",
    "list_of_words = cv.fit_transform(pos_X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d71c93",
   "metadata": {},
   "source": [
    "### 2) Running the first models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a880f",
   "metadata": {},
   "source": [
    "#### Model number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07155c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 63,738 \n",
      "The amount of time it took to vectorize was: 2.871718000000044\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3645  520]\n",
      " [ 693 3392]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      4165\n",
      "           1       0.87      0.83      0.85      4085\n",
      "\n",
      "    accuracy                           0.85      8250\n",
      "   macro avg       0.85      0.85      0.85      8250\n",
      "weighted avg       0.85      0.85      0.85      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8670756646216768\n",
      "Accuracy Score: 0.8529696969696969\n",
      "Recall Score: 0.8303549571603427\n",
      "f1 Score 0.8483181192947354\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a1d26",
   "metadata": {},
   "source": [
    "This is the base Multinominal only using basic stop words in english. It is using a basic ngram_range of 1,1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6e38d",
   "metadata": {},
   "source": [
    "#### Model number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e570d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 2,991,762 \n",
      "The amount of time it took to vectorize was: 14.126662\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3663  474]\n",
      " [ 545 3568]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8827313211281543\n",
      "Accuracy Score: 0.8764848484848485\n",
      "Recall Score: 0.8674933138828106\n",
      "f1 Score 0.8750459840588596\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eba6da",
   "metadata": {},
   "source": [
    "The second model performs better, specially in recall. However it takes too much time to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d499e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 2,446,414 \n",
      "The amount of time it took to vectorize was: 12.615819999999985\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3610  499]\n",
      " [ 559 3582]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      4109\n",
      "           1       0.88      0.87      0.87      4141\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8777260475373683\n",
      "Accuracy Score: 0.8717575757575757\n",
      "Recall Score: 0.8650084520647187\n",
      "f1 Score 0.8713208465093653\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "X_train_sample = X_train.sample(frac=.8, random_state=50)\n",
    "y_train_sample = y_train.sample(frac=.8, random_state=50)\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train_sample, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train_sample)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b6fa3",
   "metadata": {},
   "source": [
    "Feeding the model with less amount of data; seems to make the model run worse, which was expected. I need to check with an a/b testing though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc5a1c",
   "metadata": {},
   "source": [
    "#### Model number 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "635a74ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 5,342,619 \n",
      "The amount of time it took to vectorize was: 21.06203400000001\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3643  494]\n",
      " [ 527 3586]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4137\n",
      "           1       0.88      0.87      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.878921568627451\n",
      "Accuracy Score: 0.8762424242424243\n",
      "Recall Score: 0.8718696814976903\n",
      "f1 Score 0.8753814231661174\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,5))\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train_sample, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train_sample)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b4b025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 6,608,794 \n",
      "The amount of time it took to vectorize was: 30.867364000000002\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3611  526]\n",
      " [ 455 3658]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      4137\n",
      "           1       0.87      0.89      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.874282982791587\n",
      "Accuracy Score: 0.881090909090909\n",
      "Recall Score: 0.8893751519572088\n",
      "f1 Score 0.8817644931903098\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,5) , max_df=.1)\n",
    "\n",
    "for vec ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    \n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ecd56",
   "metadata": {},
   "source": [
    "#### Model number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e2ef4d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 16.878854000000004\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "stop_words = 'the and of to is in br it that this as with for was film movie his on are have be one'.split(' ')\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3))\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e4097",
   "metadata": {},
   "source": [
    "This was a mechanical way to extract words but I have an idea of how to authomate the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe20d32",
   "metadata": {},
   "source": [
    "### 3) Tweeking Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2071e",
   "metadata": {},
   "source": [
    "#### Max df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bc6d6",
   "metadata": {},
   "source": [
    "Max_df and min_df are use to eliminate words based on some threshold. The idea is that some tokens instead of helping\n",
    "the model are only noise.\n",
    "<br>There are two basic approaches to handle this types of words. We can eliminate very common words(using **max_df**) or we can eliminate very rare words using min_df.\n",
    "<br><br> The idea with max_df is that if a word appears at least in a certain percentage of the sample then it should be removed.\n",
    "<br><br> The idea with min_df is that if a word appears in less document that in the theshold it should be ignored. \n",
    "<br><br> Notice that max_df will have a lot of overlapping with stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4783ca4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 0.4\n",
      "(16750, 3713413)\n",
      "This is the shape for 0.5\n",
      "(16750, 3713428)\n",
      "This is the shape for 0.6\n",
      "(16750, 3713440)\n",
      "This is the shape for 0.7\n",
      "(16750, 3713446)\n",
      "This is the shape for 0.8\n",
      "(16750, 3713448)\n",
      "This is the shape for 0.9\n",
      "(16750, 3713452)\n",
      "This is the shape for 1.0\n",
      "(16750, 3713457)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,11,1):\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=i/10)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i/10}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9808131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 0.4\n",
      "(16750, 63655)\n",
      "This is the shape for 0.5\n",
      "(16750, 63670)\n",
      "This is the shape for 0.6\n",
      "(16750, 63680)\n",
      "This is the shape for 0.7\n",
      "(16750, 63685)\n",
      "This is the shape for 0.8\n",
      "(16750, 63687)\n",
      "This is the shape for 0.9\n",
      "(16750, 63691)\n",
      "This is the shape for 1.0\n",
      "(16750, 63696)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,11,1):\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,1), max_df=i/10)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i/10}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38a720",
   "metadata": {},
   "source": [
    "I don't see much of a difference in this max_df, even at really low percentages. But, never know if this can really affect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "851aa8e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>character</td>\n",
       "      <td>4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>films</td>\n",
       "      <td>4627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>life</td>\n",
       "      <td>4399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where</td>\n",
       "      <td>4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plot</td>\n",
       "      <td>4349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>little</td>\n",
       "      <td>4309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>show</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>love</td>\n",
       "      <td>4287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>over</td>\n",
       "      <td>4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>best</td>\n",
       "      <td>4199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>did</td>\n",
       "      <td>4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>know</td>\n",
       "      <td>4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>does</td>\n",
       "      <td>4065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>off</td>\n",
       "      <td>4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ever</td>\n",
       "      <td>3982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>man</td>\n",
       "      <td>3980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>better</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>here</td>\n",
       "      <td>3884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>end</td>\n",
       "      <td>3807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>your</td>\n",
       "      <td>3794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  counts\n",
       "0   character    4746\n",
       "1       films    4627\n",
       "2        life    4399\n",
       "3       where    4350\n",
       "4        plot    4349\n",
       "5      little    4309\n",
       "6        show    4296\n",
       "7        love    4287\n",
       "8        over    4270\n",
       "9        best    4199\n",
       "10        did    4190\n",
       "11       know    4167\n",
       "12       does    4065\n",
       "13        off    4059\n",
       "14       ever    3982\n",
       "15        man    3980\n",
       "16     better    3936\n",
       "17       here    3884\n",
       "18        end    3807\n",
       "19       your    3794"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Most common words in general\n",
    "\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,1), max_df=.2)\n",
    "list_of_words = cv.fit_transform(X_train).toarray()\n",
    "sum_of_words = pd.Series(list_of_words.sum(axis=0))\n",
    "sum_of_words = sum_of_words.sort_values(ascending=False)[:20]\n",
    "\n",
    "words = []\n",
    "numbers = []\n",
    "\n",
    "for num in sum_of_words.index:\n",
    "    word = (list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(num)])\n",
    "    numbers.append(sum_of_words.loc[num])\n",
    "    words.append(word)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"words\" : words,\n",
    "    \"counts\" : numbers,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcc8bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=59)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c2100",
   "metadata": {},
   "source": [
    "#### Model number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca7d72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 80,245 \n",
      "The amount of time it took to vectorize was: 14.630815999999982\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3663  502]\n",
      " [ 529 3556]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4165\n",
      "           1       0.88      0.87      0.87      4085\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.87      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8762937407589946\n",
      "Accuracy Score: 0.875030303030303\n",
      "Recall Score: 0.8705018359853122\n",
      "f1 Score 0.8733881861721725\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=10, max_df=.4 )\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "803f4ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 17.942894000000024\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=.3)\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b73dd",
   "metadata": {},
   "source": [
    "This models perform quiet similar to the models that where run with the decided stop_words (which was expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3cd0d",
   "metadata": {},
   "source": [
    "#### Model number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddfe39c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,718,004 \n",
      "The amount of time it took to vectorize was: 18.375955000000033\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3751  386]\n",
      " [ 530 3583]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4137\n",
      "           1       0.90      0.87      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9027462836986646\n",
      "Accuracy Score: 0.888969696969697\n",
      "Recall Score: 0.8711402868952103\n",
      "f1 Score 0.886661717396684\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "stop_words = 'the and of to is in br it that this as with for was film movie his on are have be one'.split(' ')\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), max_df=.3)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(vec , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(vec, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34387d",
   "metadata": {},
   "source": [
    "There was a lot of overlap, and this little amount of words really make a difference in the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f83cc",
   "metadata": {},
   "source": [
    "#### Models using min_df alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75874e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 38025)\n",
      "This is the shape for 5\n",
      "(16750, 22483)\n",
      "This is the shape for 10\n",
      "(16750, 14804)\n",
      "This is the shape for 15\n",
      "(16750, 11432)\n",
      "This is the shape for 20\n",
      "(16750, 9375)\n",
      "This is the shape for 25\n",
      "(16750, 7969)\n",
      "This is the shape for 30\n",
      "(16750, 7034)\n",
      "This is the shape for 50\n",
      "(16750, 4803)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,10,15,20,25,30,50]:\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,1), min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c819647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 622962)\n",
      "This is the shape for 5\n",
      "(16750, 175106)\n",
      "This is the shape for 10\n",
      "(16750, 80501)\n",
      "This is the shape for 15\n",
      "(16750, 52307)\n",
      "This is the shape for 20\n",
      "(16750, 38496)\n",
      "This is the shape for 25\n",
      "(16750, 30253)\n",
      "This is the shape for 30\n",
      "(16750, 24837)\n",
      "This is the shape for 50\n",
      "(16750, 14359)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,10,15,20,25,30,50]:\n",
    "    count_vectorizer = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8c3cff7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape for 2\n",
      "(16750, 408279)\n",
      "This is the shape for 5\n",
      "(16750, 99325)\n",
      "This is the shape for 10\n",
      "(16750, 43980)\n",
      "This is the shape for 15\n",
      "(16750, 28243)\n",
      "This is the shape for 20\n",
      "(16750, 20688)\n",
      "This is the shape for 25\n",
      "(16750, 16255)\n",
      "This is the shape for 30\n",
      "(16750, 13391)\n",
      "This is the shape for 50\n",
      "(16750, 7828)\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5,10,15,20,25,30,50]:\n",
    "    count_vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), min_df=i)\n",
    "    X_train_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "    print(f'This is the shape for {i}')\n",
    "    print(X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e0b08",
   "metadata": {},
   "source": [
    "#### Model number 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28c5b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 99,325 \n",
      "The amount of time it took to vectorize was: 11.592953999999963\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3639  498]\n",
      " [ 505 3608]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      4137\n",
      "           1       0.88      0.88      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8787140769605456\n",
      "Accuracy Score: 0.8784242424242424\n",
      "Recall Score: 0.8772185752492099\n",
      "f1 Score 0.8779656892566006\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), min_df=5)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5048d13",
   "metadata": {},
   "source": [
    "#### Model number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19a7983f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 43,980 \n",
      "The amount of time it took to vectorize was: 10.890859999999975\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3592  545]\n",
      " [ 510 3603]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      4137\n",
      "           1       0.87      0.88      0.87      4113\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8686113789778206\n",
      "Accuracy Score: 0.8721212121212121\n",
      "Recall Score: 0.8760029175784099\n",
      "f1 Score 0.8722914901343661\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words=stop_words, ngram_range=(1,3), min_df=10)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e748d255",
   "metadata": {},
   "source": [
    "Lets try some mixture of both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca693001",
   "metadata": {},
   "source": [
    "#### Model number 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e6c60c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 80,433 \n",
      "The amount of time it took to vectorize was: 13.848969000000011\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3630  507]\n",
      " [ 445 3668]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4137\n",
      "           1       0.88      0.89      0.89      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.878562874251497\n",
      "Accuracy Score: 0.8846060606060606\n",
      "Recall Score: 0.8918064672988086\n",
      "f1 Score 0.8851351351351352\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=10, max_df=0.3)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2f446",
   "metadata": {},
   "source": [
    "#### Model number 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b09b3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 80,457 \n",
      "The amount of time it took to vectorize was: 15.139723000000004\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3628  509]\n",
      " [ 449 3664]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4137\n",
      "           1       0.88      0.89      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8780254013898874\n",
      "Accuracy Score: 0.8838787878787879\n",
      "Recall Score: 0.8908339411621687\n",
      "f1 Score 0.8843832971276853\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=10, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb10688",
   "metadata": {},
   "source": [
    "The combination of both doesn't look better (need more testing to check if it is the same) but it may be faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c1dde",
   "metadata": {},
   "source": [
    "#### Model number 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5db7ebc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 175,062 \n",
      "The amount of time it took to vectorize was: 13.904557000000068\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3661  476]\n",
      " [ 474 3639]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      4137\n",
      "           1       0.88      0.88      0.88      4113\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.884325637910085\n",
      "Accuracy Score: 0.8848484848484849\n",
      "Recall Score: 0.8847556528081693\n",
      "f1 Score 0.8845405930967428\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=5, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1301727",
   "metadata": {},
   "source": [
    "#### Model number 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7af35965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 622,918 \n",
      "The amount of time it took to vectorize was: 15.014494000000013\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3704  433]\n",
      " [ 467 3646]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4137\n",
      "           1       0.89      0.89      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8938465310125031\n",
      "Accuracy Score: 0.8909090909090909\n",
      "Recall Score: 0.886457573547289\n",
      "f1 Score 0.89013671875\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=2, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530642cd",
   "metadata": {},
   "source": [
    "I would like to understand exactly why when you start to increase the min_df you get a worse score if also you are working with a max_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acdfc36",
   "metadata": {},
   "source": [
    "#### Model number 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b463637",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train, new_y_train = remove_outliers(X_train, y_train , flesch_readability_ease)\n",
    "new_X_test, new_y_test = remove_outliers(X_test, y_test , flesch_readability_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ceacc618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 3,683,278 \n",
      "The amount of time it took to vectorize was: 19.877337999999995\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3698  410]\n",
      " [ 461 3611]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4108\n",
      "           1       0.90      0.89      0.89      4072\n",
      "\n",
      "    accuracy                           0.89      8180\n",
      "   macro avg       0.89      0.89      0.89      8180\n",
      "weighted avg       0.89      0.89      0.89      8180\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8980353145983586\n",
      "Accuracy Score: 0.893520782396088\n",
      "Recall Score: 0.8867878192534381\n",
      "f1 Score 0.8923761275176078\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=0.3)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, new_X_train, new_X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, new_y_train)\n",
    "    check_model(clf, X_test_vectorized, new_y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2858e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The really impresive stuff is that if you run the code only with the outliers then you get a perfect score. \n",
    "## At least in this split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04430225",
   "metadata": {},
   "source": [
    "#### Model number 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d664c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 584,934 \n",
      "The amount of time it took to vectorize was: 12.373823999999999\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3704  433]\n",
      " [ 470 3643]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4137\n",
      "           1       0.89      0.89      0.89      4113\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8937684003925417\n",
      "Accuracy Score: 0.8905454545454545\n",
      "Recall Score: 0.8857281789448092\n",
      "f1 Score 0.8897301257784832\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(2,3), min_df=2, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6e8c699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 302,349 \n",
      "The amount of time it took to vectorize was: 7.228403\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[3603  534]\n",
      " [ 548 3565]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      4137\n",
      "           1       0.87      0.87      0.87      4113\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.8697243230056111\n",
      "Accuracy Score: 0.8688484848484849\n",
      "Recall Score: 0.8667639192803307\n",
      "f1 Score 0.8682415976619582\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(3,3), min_df=2, max_df=0.4)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_test_vectorized, y_test)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58c878e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of features in the Vectorized X train is: 204,045 \n",
      "The amount of time it took to vectorize was: 12.635899000000109\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "Confusion Matrix\n",
      "[[4864   84]\n",
      " [ 146 4906]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      4948\n",
      "           1       0.98      0.97      0.98      5052\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "\n",
      "\n",
      "Other Metrics:\n",
      "Pression Score: 0.9831663326653307\n",
      "Accuracy Score: 0.977\n",
      "Recall Score: 0.9711005542359462\n",
      "f1 Score 0.9770961959768971\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=30)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), max_df=0.4, min_df=3)\n",
    "\n",
    "\n",
    "for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "    # Vectorization\n",
    "    start = time.process_time()\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "    print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "    print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "    \n",
    "    # Running the model\n",
    "    print(clf_name)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    check_model(clf, X_train_vectorized, y_train)\n",
    "    print(\"_________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fbbd3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab640e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "done in 97.034s\n",
      "\n",
      "Best score: 0.880\n",
      "Best parameters set:\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1,3), min_df=5)),\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    print(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959686cc",
   "metadata": {},
   "source": [
    "### 3.5) Tailored based stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8cc68b",
   "metadata": {},
   "source": [
    "### 4) Contrasting Models and A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b606db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is another Christian propaganda fil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman who hates cats (Alice Krige) and her s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beast Wars is a show that is over-hyped, overp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An excellent example of \"cowboy noir\", as it's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok, basically this is a popcorn sci-fi movie, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Jimmy Cagney races by your eyes constantly in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Very much a film from the times -- extremely l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>The Little Mermaid is one of my absolute favor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>With a simplistic story and an engaging heroin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The 63 year reign of Queen Victoria is perhaps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                contents  labels\n",
       "0      This movie is another Christian propaganda fil...       0\n",
       "1      A woman who hates cats (Alice Krige) and her s...       1\n",
       "2      Beast Wars is a show that is over-hyped, overp...       0\n",
       "3      An excellent example of \"cowboy noir\", as it's...       1\n",
       "4      Ok, basically this is a popcorn sci-fi movie, ...       1\n",
       "...                                                  ...     ...\n",
       "24995  Jimmy Cagney races by your eyes constantly in ...       1\n",
       "24996  Very much a film from the times -- extremely l...       0\n",
       "24997  The Little Mermaid is one of my absolute favor...       0\n",
       "24998  With a simplistic story and an engaging heroin...       1\n",
       "24999  The 63 year reign of Queen Victoria is perhaps...       1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83f69a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "for i1,i2 in kf.split(data):\n",
    "    lst1 = list(i1)\n",
    "    lst2 = list(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa6687d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer(stop_words={'english'}, ngram_range=(1,3), min_df=2, max_df=0.4)\n",
    "X = 1\n",
    "y = 1\n",
    "test_split = 1\n",
    "\n",
    "def model_run(cv, clf, model_name, X, y, test_split):\n",
    "    for cv ,clf, clf_name in [(cv , mnb, 'Multinomial Naive Bayes')]:\n",
    "        # Vectorization\n",
    "        start = time.process_time()\n",
    "        X_train_vectorized, X_test_vectorized = vectorize_X(cv, X_train, X_test)\n",
    "        print('The amount of features in the Vectorized X train is: {:,} '.format(X_train_vectorized.shape[1]))\n",
    "        print(f'The amount of time it took to vectorize was: {time.process_time() - start}\\n')\n",
    "\n",
    "        # Running the model\n",
    "        print(clf_name)\n",
    "        clf.fit(X_train_vectorized, y_train)\n",
    "        check_model(clf, X_test_vectorized, y_test)\n",
    "        print(\"_________________________________________________\")\n",
    "        \n",
    "def get_test_split():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "014b6dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12500</th>\n",
       "      <td>argh! this film hurts my head. and not in a go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12501</th>\n",
       "      <td>Istanbul is another one of those expatriate fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12502</th>\n",
       "      <td>As a history nut who is particularly intereste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12503</th>\n",
       "      <td>This is a very enjoyable film with excellent a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504</th>\n",
       "      <td>Me being of Irish origins, loved this movie, N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Jimmy Cagney races by your eyes constantly in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Very much a film from the times -- extremely l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>The Little Mermaid is one of my absolute favor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>With a simplistic story and an engaging heroin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The 63 year reign of Queen Victoria is perhaps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                contents  labels\n",
       "12500  argh! this film hurts my head. and not in a go...       0\n",
       "12501  Istanbul is another one of those expatriate fi...       0\n",
       "12502  As a history nut who is particularly intereste...       0\n",
       "12503  This is a very enjoyable film with excellent a...       1\n",
       "12504  Me being of Irish origins, loved this movie, N...       1\n",
       "...                                                  ...     ...\n",
       "24995  Jimmy Cagney races by your eyes constantly in ...       1\n",
       "24996  Very much a film from the times -- extremely l...       0\n",
       "24997  The Little Mermaid is one of my absolute favor...       0\n",
       "24998  With a simplistic story and an engaging heroin...       1\n",
       "24999  The 63 year reign of Queen Victoria is perhaps...       1\n",
       "\n",
       "[12500 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[~data.index.isin(i1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
